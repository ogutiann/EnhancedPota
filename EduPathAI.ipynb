{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSQpHMegJmhzMqQEbUx+lm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a0403ac51fb4fc6bcd0a955b14f81f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78f0cf69cc8f41188139b1be810a774b",
              "IPY_MODEL_48e8b313c0a649f3bd3b03b2258fccd3",
              "IPY_MODEL_809ab68dabef43d3bddd50a9b5dfd836"
            ],
            "layout": "IPY_MODEL_3619ee2e8d6d43e68c94248fa356a22a"
          }
        },
        "78f0cf69cc8f41188139b1be810a774b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3282f683851641518d7bdf6016e7427d",
            "placeholder": "​",
            "style": "IPY_MODEL_1fdab914a9ff437ba7fc074cf2a2b7c1",
            "value": "modules.json: 100%"
          }
        },
        "48e8b313c0a649f3bd3b03b2258fccd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f3e3a13a154847977442503ed31b96",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5352886809d840379169777439ebd883",
            "value": 349
          }
        },
        "809ab68dabef43d3bddd50a9b5dfd836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc48271bc87143e2abb6840f75de7f42",
            "placeholder": "​",
            "style": "IPY_MODEL_0ba8dadc4b5b48bca7fb3d11b0f14249",
            "value": " 349/349 [00:00&lt;00:00, 13.0kB/s]"
          }
        },
        "3619ee2e8d6d43e68c94248fa356a22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3282f683851641518d7bdf6016e7427d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fdab914a9ff437ba7fc074cf2a2b7c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5f3e3a13a154847977442503ed31b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5352886809d840379169777439ebd883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc48271bc87143e2abb6840f75de7f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba8dadc4b5b48bca7fb3d11b0f14249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e87cb9f12041e7b99b198849fb4e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35d287401d8b4bc883e455b075931add",
              "IPY_MODEL_05138b65180b4296898d1c77fad4382e",
              "IPY_MODEL_ba334feccfb140e0bd85642f1207820f"
            ],
            "layout": "IPY_MODEL_b1cd50b6230d4208943461aa20df8d7a"
          }
        },
        "35d287401d8b4bc883e455b075931add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf2c6d74473b4728964a9b933a16339a",
            "placeholder": "​",
            "style": "IPY_MODEL_bcc7f13c930340de9ea0a74b00ae3c2b",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "05138b65180b4296898d1c77fad4382e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b42fa8c985e45da81f188248604be48",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23946379f4674911a698f2727ea14733",
            "value": 116
          }
        },
        "ba334feccfb140e0bd85642f1207820f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb0424e7a14547bd904bb67352fd7f63",
            "placeholder": "​",
            "style": "IPY_MODEL_83f0960f6ef640d8a28a87cf0096b191",
            "value": " 116/116 [00:00&lt;00:00, 6.15kB/s]"
          }
        },
        "b1cd50b6230d4208943461aa20df8d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf2c6d74473b4728964a9b933a16339a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc7f13c930340de9ea0a74b00ae3c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b42fa8c985e45da81f188248604be48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23946379f4674911a698f2727ea14733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb0424e7a14547bd904bb67352fd7f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f0960f6ef640d8a28a87cf0096b191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f994796f69a2441881e7ecb23e08a2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e80dd31a9d4492da1402dd9434160e6",
              "IPY_MODEL_a90f89bc81404ed7991dbd24959ed933",
              "IPY_MODEL_36b2facb2f56451181a2cedf0efdc7d9"
            ],
            "layout": "IPY_MODEL_6c185b7cc14141b9820bb3a2570c05fc"
          }
        },
        "8e80dd31a9d4492da1402dd9434160e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f7bcaf8f76437b8a924999f9a4e11f",
            "placeholder": "​",
            "style": "IPY_MODEL_9e29d95cddb54dab8bb14aa3c5133fb9",
            "value": "README.md: "
          }
        },
        "a90f89bc81404ed7991dbd24959ed933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4577ec20788d4190a65891d424a0abdf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0961adecfc7a4063a047af73b9f9be6e",
            "value": 1
          }
        },
        "36b2facb2f56451181a2cedf0efdc7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e59fd93149934d07a749ce2fc524fdcd",
            "placeholder": "​",
            "style": "IPY_MODEL_e7d4ff72e6cd4fd89dce5c437238e4e9",
            "value": " 10.5k/? [00:00&lt;00:00, 665kB/s]"
          }
        },
        "6c185b7cc14141b9820bb3a2570c05fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f7bcaf8f76437b8a924999f9a4e11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e29d95cddb54dab8bb14aa3c5133fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4577ec20788d4190a65891d424a0abdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0961adecfc7a4063a047af73b9f9be6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e59fd93149934d07a749ce2fc524fdcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d4ff72e6cd4fd89dce5c437238e4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f0a59457b3146f09e780b2dcc64beea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_628dbc403a9f476396b740875a639d0c",
              "IPY_MODEL_f33d3b4cb2bb4b66950ee5627767029b",
              "IPY_MODEL_e6939fd60fb84cb7b4cd9d1cfff1a70d"
            ],
            "layout": "IPY_MODEL_b2c76b60e3ed46c2802bccaf3dce46b5"
          }
        },
        "628dbc403a9f476396b740875a639d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364470626d904de98d97cab389457f39",
            "placeholder": "​",
            "style": "IPY_MODEL_d46599d1c77847258b6c3b1b2e27aa51",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "f33d3b4cb2bb4b66950ee5627767029b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a8652777ec04518b884699530103090",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c279becbaf9a4339bd9d957c164d2eba",
            "value": 53
          }
        },
        "e6939fd60fb84cb7b4cd9d1cfff1a70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6600708d4e7e42ae961993c43a12ae53",
            "placeholder": "​",
            "style": "IPY_MODEL_2b693e738f9348d9aa1d2b42336c0bc8",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.01kB/s]"
          }
        },
        "b2c76b60e3ed46c2802bccaf3dce46b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364470626d904de98d97cab389457f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46599d1c77847258b6c3b1b2e27aa51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a8652777ec04518b884699530103090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c279becbaf9a4339bd9d957c164d2eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6600708d4e7e42ae961993c43a12ae53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b693e738f9348d9aa1d2b42336c0bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c753fb5996ec4ed38b098053611fd8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79424982a3084e41ae43df01414189ce",
              "IPY_MODEL_28878c11a0d344929dd31ab7425e4f20",
              "IPY_MODEL_7533e6687c0e485bab83f28914b612f5"
            ],
            "layout": "IPY_MODEL_eaeb6a09c5334be28584882414134aae"
          }
        },
        "79424982a3084e41ae43df01414189ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3533cc3c05e34f7aadb4738a1ef13e4f",
            "placeholder": "​",
            "style": "IPY_MODEL_75d5c5524bb7435d81d7d16077a76a70",
            "value": "config.json: 100%"
          }
        },
        "28878c11a0d344929dd31ab7425e4f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eaf02b37fec482c9df962b06b9ae7f2",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c1a80ae625d4626b80cbf389fe8e86a",
            "value": 612
          }
        },
        "7533e6687c0e485bab83f28914b612f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1760b48d62142f2bbcbfa1ef00e07fc",
            "placeholder": "​",
            "style": "IPY_MODEL_0a44318c514f41fa95aea0b28dc3f452",
            "value": " 612/612 [00:00&lt;00:00, 31.5kB/s]"
          }
        },
        "eaeb6a09c5334be28584882414134aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3533cc3c05e34f7aadb4738a1ef13e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d5c5524bb7435d81d7d16077a76a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eaf02b37fec482c9df962b06b9ae7f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1a80ae625d4626b80cbf389fe8e86a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1760b48d62142f2bbcbfa1ef00e07fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a44318c514f41fa95aea0b28dc3f452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d48e933c0804403e8e94a570a294caf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d54e7b447efa41f4a99f42af38f78a7b",
              "IPY_MODEL_10817afe07ab43518eb4166275e277a8",
              "IPY_MODEL_ce93493cbe154119b985339cfbc7d0e1"
            ],
            "layout": "IPY_MODEL_04a5a874972d430e9074e20713e422fb"
          }
        },
        "d54e7b447efa41f4a99f42af38f78a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4a732ea3b24284952f4d1b17b8eb59",
            "placeholder": "​",
            "style": "IPY_MODEL_8f1bb645f78749cda653d2ac08c1344b",
            "value": "model.safetensors: 100%"
          }
        },
        "10817afe07ab43518eb4166275e277a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_509c7dee1f704090a19d68d016bdaa9c",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bae64d6f0dbc4928b5cf7b3667e3dd92",
            "value": 90868376
          }
        },
        "ce93493cbe154119b985339cfbc7d0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed346799da8d47e6a5fbcfe2b3c3a0d7",
            "placeholder": "​",
            "style": "IPY_MODEL_209cfeebe9bb4b6a966f47837920f24d",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 89.1MB/s]"
          }
        },
        "04a5a874972d430e9074e20713e422fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4a732ea3b24284952f4d1b17b8eb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1bb645f78749cda653d2ac08c1344b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "509c7dee1f704090a19d68d016bdaa9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae64d6f0dbc4928b5cf7b3667e3dd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed346799da8d47e6a5fbcfe2b3c3a0d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "209cfeebe9bb4b6a966f47837920f24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0abc712f469464f99537622f03e4ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebed7b1af90d4584b736ba0801165191",
              "IPY_MODEL_8a3991a2480443c1ad13fbf5a5fd4697",
              "IPY_MODEL_2ebd7286daff47fb89b83e26275ebd97"
            ],
            "layout": "IPY_MODEL_dbbe01671a38421b8235b990663ad8bf"
          }
        },
        "ebed7b1af90d4584b736ba0801165191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719bed6773504ba2971b3d16c9b523d8",
            "placeholder": "​",
            "style": "IPY_MODEL_754ee199001747d0a04dbe0ba2405706",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8a3991a2480443c1ad13fbf5a5fd4697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_173f1361e49d41ad89f13077c155941d",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48d8a1e7c12c447d8e7fd087f1a5cf4f",
            "value": 350
          }
        },
        "2ebd7286daff47fb89b83e26275ebd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae5795e012c141e1b429ce4a7f504978",
            "placeholder": "​",
            "style": "IPY_MODEL_23649b55e1764633baffdb93b4bf0756",
            "value": " 350/350 [00:00&lt;00:00, 28.1kB/s]"
          }
        },
        "dbbe01671a38421b8235b990663ad8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719bed6773504ba2971b3d16c9b523d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "754ee199001747d0a04dbe0ba2405706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "173f1361e49d41ad89f13077c155941d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d8a1e7c12c447d8e7fd087f1a5cf4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae5795e012c141e1b429ce4a7f504978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23649b55e1764633baffdb93b4bf0756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1a31dacceab40ed87be786ef24ff155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddf2601798bc4c9c9a3e0051dd14ceab",
              "IPY_MODEL_87012343534e48a0b0065dc16e5f81fb",
              "IPY_MODEL_785ed485f6104be3a3b94ab1cecd07dd"
            ],
            "layout": "IPY_MODEL_acd2ed93ba0c4ff1afbf544b37b5350e"
          }
        },
        "ddf2601798bc4c9c9a3e0051dd14ceab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d9e18f1583040dbbb3b62f58dc0620d",
            "placeholder": "​",
            "style": "IPY_MODEL_8db05105cb274fe297dd3abb743560ec",
            "value": "vocab.txt: "
          }
        },
        "87012343534e48a0b0065dc16e5f81fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_145610807a114956b504ef6465de2e16",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5319c41b7364528beb8610d3c584c4b",
            "value": 1
          }
        },
        "785ed485f6104be3a3b94ab1cecd07dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dac60cdd59d4c45823283978a714d14",
            "placeholder": "​",
            "style": "IPY_MODEL_cabf6c864b7744eaad7666630f6bde85",
            "value": " 232k/? [00:00&lt;00:00, 8.63MB/s]"
          }
        },
        "acd2ed93ba0c4ff1afbf544b37b5350e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d9e18f1583040dbbb3b62f58dc0620d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db05105cb274fe297dd3abb743560ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "145610807a114956b504ef6465de2e16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d5319c41b7364528beb8610d3c584c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dac60cdd59d4c45823283978a714d14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cabf6c864b7744eaad7666630f6bde85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47e55332e60848eab31576b92959a59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7658afcf3af7447095f71c847e4d92e2",
              "IPY_MODEL_c6bb36b19140424f938cdbc5638506bc",
              "IPY_MODEL_0413c084b439479da41791f1e5d876ec"
            ],
            "layout": "IPY_MODEL_49737dae0aaa4b19a069c8dbc56a14f3"
          }
        },
        "7658afcf3af7447095f71c847e4d92e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcf0e7df07d04b589fa694cb167d0e3d",
            "placeholder": "​",
            "style": "IPY_MODEL_363633835ca8468e972c9f380504e474",
            "value": "tokenizer.json: "
          }
        },
        "c6bb36b19140424f938cdbc5638506bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9baa9454fbe4e2eac0305a199f965e5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02f58656b18f48af8e192e0dfad7a7cf",
            "value": 1
          }
        },
        "0413c084b439479da41791f1e5d876ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce8fe6fe5f34a978d9bdd7ad120f7eb",
            "placeholder": "​",
            "style": "IPY_MODEL_3610aa9a3cf5472eaec720e487f6c876",
            "value": " 466k/? [00:00&lt;00:00, 19.2MB/s]"
          }
        },
        "49737dae0aaa4b19a069c8dbc56a14f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf0e7df07d04b589fa694cb167d0e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363633835ca8468e972c9f380504e474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9baa9454fbe4e2eac0305a199f965e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "02f58656b18f48af8e192e0dfad7a7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ce8fe6fe5f34a978d9bdd7ad120f7eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3610aa9a3cf5472eaec720e487f6c876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b818284cb19842f995e87f92636e85ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea1aa1a1450c48548062f2c37abfb256",
              "IPY_MODEL_284e17c70c4344cc93a67019c0e0006f",
              "IPY_MODEL_1cc610b04752452cad712b59062a6be3"
            ],
            "layout": "IPY_MODEL_2dc2975ba38e4995ad3b0c2b0efb80f1"
          }
        },
        "ea1aa1a1450c48548062f2c37abfb256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11a1658f96344569130f89c440b800e",
            "placeholder": "​",
            "style": "IPY_MODEL_e003c9f4d37048efac24a2737abef176",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "284e17c70c4344cc93a67019c0e0006f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a332ffd8516454ebb131a413346ad7f",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c68efda1b8f4621aff8548060cb98d4",
            "value": 112
          }
        },
        "1cc610b04752452cad712b59062a6be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e17882eaf4394fd0baf62396ffc9e27d",
            "placeholder": "​",
            "style": "IPY_MODEL_86e820c50e5b481bbb270c30c44adf74",
            "value": " 112/112 [00:00&lt;00:00, 5.17kB/s]"
          }
        },
        "2dc2975ba38e4995ad3b0c2b0efb80f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11a1658f96344569130f89c440b800e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e003c9f4d37048efac24a2737abef176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a332ffd8516454ebb131a413346ad7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c68efda1b8f4621aff8548060cb98d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e17882eaf4394fd0baf62396ffc9e27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e820c50e5b481bbb270c30c44adf74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f91ec36bb33746f4a96afec472449efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bd15926344d461e86feb19d4fcdd808",
              "IPY_MODEL_910e5b71cd2e4fc99ece6e20197d74c9",
              "IPY_MODEL_d4729d1126494969b746aa2abe47e0d0"
            ],
            "layout": "IPY_MODEL_526499a068884bd3a653e12253b30cb6"
          }
        },
        "2bd15926344d461e86feb19d4fcdd808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4e5f7113c384e32af74b9bc2e1e8aee",
            "placeholder": "​",
            "style": "IPY_MODEL_29129740e4444cf9ad6ffc5d0a08b37a",
            "value": "config.json: 100%"
          }
        },
        "910e5b71cd2e4fc99ece6e20197d74c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fef5826f6474ced86abfefb5f333d99",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_540563949bd64dfbb9f6363e070d5d59",
            "value": 190
          }
        },
        "d4729d1126494969b746aa2abe47e0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36d86e044bab44a4b62e61d703d88d16",
            "placeholder": "​",
            "style": "IPY_MODEL_867ca38d3a1041b3b36b29aa7be7ebf2",
            "value": " 190/190 [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "526499a068884bd3a653e12253b30cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e5f7113c384e32af74b9bc2e1e8aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29129740e4444cf9ad6ffc5d0a08b37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fef5826f6474ced86abfefb5f333d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540563949bd64dfbb9f6363e070d5d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36d86e044bab44a4b62e61d703d88d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867ca38d3a1041b3b36b29aa7be7ebf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16ee8fdbfa9d4bcdbb61b8c6f460ea2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ae17254226c42ebb026a0e50a703644",
              "IPY_MODEL_e9fe988e2d2c4702b21260c39819c908",
              "IPY_MODEL_f70f7d542f1f4b6395b943aad739274e"
            ],
            "layout": "IPY_MODEL_2453638efe30469ebf24e104b65710cf"
          }
        },
        "4ae17254226c42ebb026a0e50a703644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6636c996a0947e18d23f2af743d33b8",
            "placeholder": "​",
            "style": "IPY_MODEL_d269babdbb3d41d09cfd8f10530f6776",
            "value": "Computing widget examples:   0%"
          }
        },
        "e9fe988e2d2c4702b21260c39819c908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f04850d0a5b4fa0ac0bbbecead4ff0d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9989aeeaf5714c43b4aafdfa2d408b96",
            "value": 1
          }
        },
        "f70f7d542f1f4b6395b943aad739274e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8126f58e61ed413199f34c0e98d582df",
            "placeholder": "​",
            "style": "IPY_MODEL_dd447498aef647d5a8d992b15462ec72",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "2453638efe30469ebf24e104b65710cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e6636c996a0947e18d23f2af743d33b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d269babdbb3d41d09cfd8f10530f6776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f04850d0a5b4fa0ac0bbbecead4ff0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9989aeeaf5714c43b4aafdfa2d408b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8126f58e61ed413199f34c0e98d582df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd447498aef647d5a8d992b15462ec72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogutiann/EnhancedPota/blob/main/EduPathAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Sankofa Pathways: AI-Blockchain Adaptive Learning System\n",
        "Core Implementation for Soroti University Case Study\n",
        "\"\"\"\n",
        "import sys\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import DBSCAN, KMeans  # Added for density-based clustering\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score  # Added cluster validation\n",
        "from sentence_transformers import SentenceTransformer, datasets\n",
        "from scipy.stats import laplace\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import hashlib\n",
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "import psutil\n",
        "# Add to top imports\n",
        "from sentence_transformers import SentenceTransformer, models, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "import nltk\n",
        "\n",
        "\n",
        "# Add these to your top-level imports\n",
        "try:\n",
        "    from gensim.corpora import Dictionary\n",
        "    from gensim.models import CoherenceModel\n",
        "    GENSIM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GENSIM_AVAILABLE = False\n",
        "    print(\"Gensim not installed. Topic coherence metrics disabled.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    from umap import UMAP\n",
        "    UMAP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    UMAP_AVAILABLE = False\n",
        "    print(\"UMAP not installed. Using PCA instead.\")\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "# Add to top imports\n",
        "try:\n",
        "    from hdbscan import HDBSCAN\n",
        "    HDBSCAN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    HDBSCAN_AVAILABLE = False\n",
        "    print(\"HDBSCAN not installed. Using KMeans for clustering.\")\n",
        "\n",
        "# =====================\n",
        "# 0. CONFIGURATION\n",
        "# =====================\n",
        "PRODUCTION_MODE = False # if PRODUCTION_MODE = True  # This prevents model evaluation, set to false and reproducibility mode to true to enable evaluation\n",
        "REPRODUCIBILITY_MODE = True\n",
        "FINE_TUNE_BERT = True  # Global flag to enable/disable fine-tuning\n",
        "IN_COLAB = 'google.colab' in sys.modules  # Detect Colab environment\n",
        "\n",
        "if REPRODUCIBILITY_MODE:\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "    os.environ['PYTHONHASHSEED'] = '42'\n",
        "\n",
        "# Fixed dataset filename\n",
        "DATASET_FILENAME = \"soroti_engineering_dataset.csv\"\n",
        "TEMPLATES_FILENAME = \"assessment_templates.csv\"\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# =====================\n",
        "# 1. DATA PREPROCESSING\n",
        "# =====================\n",
        "\n",
        "class DataPreprocessor:\n",
        "    \"\"\"\n",
        "    Handles data ingestion, anonymization, and normalization\n",
        "    Implements ε-differential privacy (ε=0.85) per Uganda's Data Protection Act\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon=0.85):\n",
        "        self.epsilon = epsilon\n",
        "        self.imputer = SimpleImputer(strategy='median')\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def validate_data(self, df):\n",
        "        \"\"\"Ensure data quality before processing\"\"\"\n",
        "        if df.isnull().sum().sum() > 0:\n",
        "            print(f\"Warning: Found {df.isnull().sum().sum()} missing values. Imputing...\")\n",
        "            df = self.imputer.fit_transform(df)\n",
        "        return df\n",
        "\n",
        "    def anonymize_ids(self, student_ids):\n",
        "        \"\"\"Apply SHA-256 hashing to student identifiers\"\"\"\n",
        "        return [hashlib.sha256(str(id).encode()).hexdigest() for id in student_ids]\n",
        "\n",
        "    def add_laplace_noise(self, scores, sensitivity=12):\n",
        "        \"\"\"Inject Laplace noise for differential privacy with reproducibility option\"\"\"\n",
        "        scale = sensitivity / self.epsilon\n",
        "\n",
        "        if REPRODUCIBILITY_MODE:\n",
        "            rng = np.random.default_rng(42)\n",
        "            noise = rng.laplace(scale=scale, size=len(scores))\n",
        "        else:\n",
        "            noise = np.random.laplace(scale=scale, size=len(scores))\n",
        "\n",
        "        return scores + noise\n",
        "\n",
        "    def normalize_scores(self, scores):\n",
        "        \"\"\"Robust z-score standardization by course\"\"\"\n",
        "        return (scores - np.nanmedian(scores)) / (np.nanstd(scores) + 1e-8)\n",
        "\n",
        "    def preprocess(self, raw_data):\n",
        "        \"\"\"\n",
        "        Full preprocessing pipeline:\n",
        "        1. Create ID mapping before anonymization\n",
        "        2. Anonymize student IDs\n",
        "        3. Add Laplace noise to scores\n",
        "        4. Normalize scores by course\n",
        "        \"\"\"\n",
        "        # Create deep copy to avoid mutation\n",
        "        data = raw_data.copy()\n",
        "\n",
        "        # Create ID mapping BEFORE anonymization\n",
        "        self.id_mapping = {id: hashlib.sha256(str(id).encode()).hexdigest()\n",
        "                           for id in data['student_id'].unique()}\n",
        "\n",
        "        # Anonymization using mapping\n",
        "        data['hashed_id'] = data['student_id'].map(self.id_mapping)\n",
        "\n",
        "        # Differential privacy\n",
        "        for course in data['course'].unique():\n",
        "            mask = data['course'] == course\n",
        "            scores = data.loc[mask, 'score'].values\n",
        "            data.loc[mask, 'score'] = self.add_laplace_noise(scores)\n",
        "\n",
        "        # Normalization\n",
        "        for course in data['course'].unique():\n",
        "            mask = data['course'] == course\n",
        "            scores = data.loc[mask, 'score'].values\n",
        "            data.loc[mask, 'z_score'] = self.normalize_scores(scores)\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "# ========================\n",
        "# 2. HYBRID TOPIC MODELING\n",
        "# ========================\n",
        "\n",
        "class HybridTopicModel:\n",
        "    \"\"\"\n",
        "    Principled integration of contextual embeddings (BERT) and probabilistic modeling (LDA)\n",
        "    using topic alignment and semantic coherence measures\n",
        "    Enhanced hybrid model with fine-tuned alignment\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lambda_weight=0.65, n_topics=5, fine_tune_steps=100):\n",
        "        self.bert_model = self.load_bert_model()\n",
        "        self.lda_model = None\n",
        "        self.vectorizer = None\n",
        "        self.lambda_weight = lambda_weight\n",
        "        self.n_topics = n_topics\n",
        "        self.topic_embeddings = None\n",
        "        self.fine_tune_steps = fine_tune_steps\n",
        "        self.word_embeddings = None\n",
        "\n",
        "    def load_bert_model(self):\n",
        "        \"\"\"Robust model loading with explicit Sentence Transformer\"\"\"\n",
        "        try:\n",
        "            print(\"Loading model: sentence-transformers/all-MiniLM-L6-v2\")\n",
        "            model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading BERT model: {str(e)}. Using dummy embeddings.\")\n",
        "            return self.DummyEmbedder()\n",
        "\n",
        "    class DummyEmbedder:\n",
        "        def __init__(self, dim=384):\n",
        "            self.dim = dim\n",
        "\n",
        "        def encode(self, texts):\n",
        "            if isinstance(texts, str):\n",
        "                return np.random.randn(self.dim)\n",
        "            return [np.random.randn(self.dim) for _ in texts]\n",
        "\n",
        "    def fine_tune_bert(self, documents):\n",
        "        \"\"\"Fine-tune BERT with educational texts using paired examples\"\"\"\n",
        "        if not FINE_TUNE_BERT or not IN_COLAB:\n",
        "            print(\"Fine-tuning disabled or not in Colab. Skipping.\")\n",
        "            return\n",
        "        if isinstance(documents, np.ndarray):\n",
        "            documents = documents.tolist()\n",
        "        if not documents or len(documents) < 1:\n",
        "            print(\"Warning: No documents for fine-tuning BERT. Skipping.\")\n",
        "            return\n",
        "\n",
        "        # Create paired InputExamples (anchor and positive are the same document)\n",
        "        examples = []\n",
        "        for doc in documents:\n",
        "            examples.append(InputExample(texts=[doc, doc], label=1.0))  # Label 1.0 for positive pair\n",
        "        train_dataloader = DataLoader(examples, shuffle=True, batch_size=8)\n",
        "\n",
        "        train_loss = losses.CosineSimilarityLoss(self.bert_model)\n",
        "        self.bert_model.fit(\n",
        "            train_objectives=[(train_dataloader, train_loss)],\n",
        "            epochs=self.fine_tune_steps // len(documents) + 1,\n",
        "            warmup_steps=10,\n",
        "            output_path=\"fine_tuned_bert_model\",\n",
        "            use_amp=False\n",
        "        )\n",
        "\n",
        "    def train_lda(self, documents):\n",
        "        # FIXED: Properly handle NumPy arrays\n",
        "        if documents is None or len(documents) == 0:\n",
        "            print(\"Warning: No documents for LDA training. Using default model.\")\n",
        "            self.lda_model = LatentDirichletAllocation(n_components=self.n_topics, random_state=42)\n",
        "            return\n",
        "\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section', 'example', 'problem',\n",
        "                               'solution', 'study', 'learn']\n",
        "        self.vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english', ngram_range=(1, 2),\n",
        "                                          max_features=1000)\n",
        "        self.vectorizer.stop_words_ = set(list(self.vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.vectorizer.fit_transform(documents)\n",
        "\n",
        "        if GENSIM_AVAILABLE:\n",
        "            best_coherence = -1\n",
        "            for alpha in [0.1, 0.5, 1.0]:\n",
        "                for eta in [0.01, 0.1]:\n",
        "                    lda = LatentDirichletAllocation(\n",
        "                        n_components=self.n_topics,\n",
        "                        learning_method='online',\n",
        "                        learning_offset=10.,\n",
        "                        random_state=42,\n",
        "                        max_iter=15,\n",
        "                        n_jobs=1,\n",
        "                        doc_topic_prior=alpha,\n",
        "                        topic_word_prior=eta\n",
        "                    )\n",
        "                    lda.fit(dtm)\n",
        "                    # Extract topics manually for CoherenceModel\n",
        "                    feature_names = self.vectorizer.get_feature_names_out()\n",
        "                    topics = [[feature_names[i] for i in topic.argsort()[:-11:-1]] for topic in lda.components_]\n",
        "                    coherence_model = CoherenceModel(\n",
        "                        topics=topics,\n",
        "                        texts=[doc.split() for doc in documents],\n",
        "                        dictionary=Dictionary([doc.split() for doc in documents]),\n",
        "                        coherence='c_v'\n",
        "                    )\n",
        "                    coherence = coherence_model.get_coherence()\n",
        "                    if coherence > best_coherence:\n",
        "                        best_coherence = coherence\n",
        "                        self.lda_model = lda\n",
        "        else:\n",
        "            print(\"Gensim not available. Using default LDA model.\")\n",
        "            self.lda_model = LatentDirichletAllocation(\n",
        "                n_components=self.n_topics,\n",
        "                random_state=42,\n",
        "                max_iter=15,\n",
        "                n_jobs=1\n",
        "            )\n",
        "            self.lda_model.fit(dtm)\n",
        "\n",
        "        # FIXED TOPIC TERM GENERATION\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "        top_indices = self.lda_model.components_.argsort(axis=1)[:, ::-1][:, :10]\n",
        "        self.topic_terms = [feature_names[i] for row in top_indices for i in row]\n",
        "\n",
        "    def compute_topic_embeddings(self, documents):\n",
        "        \"\"\"Enhanced topic embedding calculation with documents parameter\"\"\"\n",
        "        # Get document embeddings\n",
        "        doc_embeddings = self.bert_model.encode(documents)\n",
        "\n",
        "        # Cluster documents using BERT embeddings\n",
        "        kmeans = KMeans(n_clusters=self.n_topics, random_state=42)\n",
        "        doc_clusters = kmeans.fit_predict(doc_embeddings)\n",
        "        cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "        # Get LDA topic-word distributions\n",
        "        topic_word_dist = self.lda_model.components_ / self.lda_model.components_.sum(axis=1)[:, np.newaxis]\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "\n",
        "        # Create enhanced topic embeddings\n",
        "        self.topic_embeddings = []\n",
        "        for i in range(self.n_topics):\n",
        "            # Get top words for LDA topic\n",
        "            top_word_indices = topic_word_dist[i].argsort()[::-1][:15]\n",
        "            top_words = [feature_names[idx] for idx in top_word_indices]\n",
        "\n",
        "            # Get most representative documents for BERT cluster\n",
        "            cluster_docs = [doc for j, doc in enumerate(documents) if doc_clusters[j] == i]\n",
        "            if cluster_docs:\n",
        "                # Encode cluster documents and average\n",
        "                cluster_embeddings = self.bert_model.encode(cluster_docs)\n",
        "                cluster_avg = np.mean(cluster_embeddings, axis=0)\n",
        "            else:\n",
        "                cluster_avg = cluster_centers[i]\n",
        "\n",
        "            # Encode LDA top words and average\n",
        "            word_embeddings = self.bert_model.encode(top_words)\n",
        "            word_avg = np.mean(word_embeddings, axis=0)\n",
        "\n",
        "            # Combine cluster and word embeddings\n",
        "            combined_embedding = (self.lambda_weight * cluster_avg +\n",
        "                                  (1 - self.lambda_weight) * word_avg)\n",
        "            self.topic_embeddings.append(combined_embedding)\n",
        "\n",
        "        self.topic_embeddings = np.array(self.topic_embeddings)\n",
        "\n",
        "    def get_document_topic_distribution(self, documents):\n",
        "        \"\"\"Improved distribution using semantic similarity\"\"\"\n",
        "        doc_embeddings = self.bert_model.encode(documents)\n",
        "        sim_matrix = cosine_similarity(doc_embeddings, self.topic_embeddings)\n",
        "\n",
        "        # Get LDA distribution\n",
        "        dtm = self.vectorizer.transform(documents)\n",
        "        lda_dist = self.lda_model.transform(dtm)\n",
        "\n",
        "        # Combine distributions\n",
        "        hybrid_dist = (self.lambda_weight * sim_matrix +\n",
        "                       (1 - self.lambda_weight) * lda_dist)\n",
        "\n",
        "        # Softmax normalization\n",
        "        hybrid_dist = np.exp(hybrid_dist) / np.sum(np.exp(hybrid_dist), axis=1, keepdims=True)\n",
        "        return hybrid_dist\n",
        "\n",
        "    def get_dominant_topic(self, documents):\n",
        "        \"\"\"Extract dominant topic\"\"\"\n",
        "        hybrid_dist = self.get_document_topic_distribution(documents)\n",
        "        return np.argmax(hybrid_dist, axis=1)\n",
        "\n",
        "# ========================\n",
        "# 2. Enhanced HYBRID TOPIC MODELING\n",
        "# ========================\n",
        "\n",
        "class EnhancedHybridTopicModel:\n",
        "    \"\"\"Paper-inspired hybrid model with UMAP, per-cluster topics, and optimal transport\"\"\"\n",
        "\n",
        "    def __init__(self, lambda_weight=0.85, n_topics=5, fine_tune_steps=200):\n",
        "        self.bert_model = self.load_bert_model()\n",
        "        self.lda_model = None\n",
        "        self.vectorizer = None\n",
        "        self.lambda_weight = lambda_weight\n",
        "        self.n_topics = n_topics\n",
        "        self.topic_embeddings = None\n",
        "        self.fine_tune_steps = fine_tune_steps\n",
        "        self.cluster_model = None\n",
        "        self.reducer = None\n",
        "        self.global_lda_model = None\n",
        "        self.global_vectorizer = None\n",
        "        self.cluster_lda_models = {}\n",
        "        self.cluster_vectorizers = {}\n",
        "        # Add dynamic topic range\n",
        "        self.min_topics = max(3, n_topics - 2)\n",
        "        self.max_topics = n_topics + 3\n",
        "\n",
        "        # Add coherence optimizer\n",
        "        self.coherence_threshold = 0.6\n",
        "\n",
        "    def load_bert_model(self):\n",
        "        \"\"\"Robust model loading with explicit Sentence Transformer\"\"\"\n",
        "        try:\n",
        "            print(\"Loading model: sentence-transformers/all-MiniLM-L6-v2\")\n",
        "            return SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading BERT model: {str(e)}. Using dummy embeddings.\")\n",
        "            return self.DummyEmbedder()\n",
        "\n",
        "    class DummyEmbedder:\n",
        "        def __init__(self, dim=384):\n",
        "            self.dim = dim\n",
        "\n",
        "        def encode(self, texts):\n",
        "            if isinstance(texts, str):\n",
        "                return np.random.randn(self.dim)\n",
        "            return [np.random.randn(self.dim) for _ in texts]\n",
        "\n",
        "    def fine_tune_bert(self, documents):\n",
        "        \"\"\"Fine-tune BERT with educational texts using paired examples\"\"\"\n",
        "        if not FINE_TUNE_BERT or not IN_COLAB:\n",
        "            print(\"Fine-tuning disabled or not in Colab. Skipping.\")\n",
        "            return\n",
        "        if isinstance(documents, np.ndarray):\n",
        "            documents = documents.tolist()\n",
        "        if not documents or len(documents) < 1:\n",
        "            print(\"Warning: No documents for fine-tuning BERT. Skipping.\")\n",
        "            return\n",
        "\n",
        "        # Create paired InputExamples (anchor and positive are the same document)\n",
        "        examples = []\n",
        "        for doc in documents:\n",
        "            examples.append(InputExample(texts=[doc, doc], label=1.0))\n",
        "        train_dataloader = DataLoader(examples, shuffle=True, batch_size=8)\n",
        "\n",
        "        train_loss = losses.CosineSimilarityLoss(self.bert_model)\n",
        "        self.bert_model.fit(\n",
        "            train_objectives=[(train_dataloader, train_loss)],\n",
        "            epochs=self.fine_tune_steps // len(documents) + 1,\n",
        "            warmup_steps=10,\n",
        "            output_path=\"fine_tuned_bert_model\",\n",
        "            use_amp=False\n",
        "        )\n",
        "\n",
        "    def reduce_dimensions(self, embeddings):\n",
        "        \"\"\"Apply UMAP or PCA dimensionality reduction\"\"\"\n",
        "        if UMAP_AVAILABLE:\n",
        "            self.reducer = UMAP(n_components=50, random_state=42, n_neighbors=15, min_dist=0.1)\n",
        "            return self.reducer.fit_transform(embeddings)\n",
        "        else:\n",
        "            print(\"Using PCA for dimensionality reduction\")\n",
        "            self.reducer = PCA(n_components=50, random_state=42)\n",
        "            return self.reducer.fit_transform(embeddings)\n",
        "\n",
        "    def cluster_documents(self, reduced_embeddings):\n",
        "        \"\"\"Cluster documents using reduced embeddings\"\"\"\n",
        "        self.cluster_model = KMeans(n_clusters=self.n_topics, random_state=42)\n",
        "        return self.cluster_model.fit_predict(reduced_embeddings)\n",
        "\n",
        "    def train_global_lda(self, documents):\n",
        "        \"\"\"Train global LDA model as fallback\"\"\"\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section',\n",
        "                               'example', 'problem', 'solution', 'study', 'learn']\n",
        "        self.global_vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english',\n",
        "                                                 ngram_range=(1, 2), max_features=1000)\n",
        "        self.global_vectorizer.stop_words_ = set(list(self.global_vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.global_vectorizer.fit_transform(documents)\n",
        "\n",
        "        self.global_lda_model = LatentDirichletAllocation(\n",
        "            n_components=self.n_topics,\n",
        "            random_state=42,\n",
        "            max_iter=15\n",
        "        )\n",
        "        self.global_lda_model.fit(dtm)\n",
        "        return self.global_lda_model\n",
        "\n",
        "    def train_lda_per_cluster(self, documents, clusters):\n",
        "        \"\"\"Train separate LDA models for each cluster\"\"\"\n",
        "        for cluster_id in range(self.n_topics):\n",
        "            cluster_docs = [doc for i, doc in enumerate(documents) if clusters[i] == cluster_id]\n",
        "\n",
        "            if len(cluster_docs) < 10:  # Minimum documents threshold\n",
        "                print(f\"Cluster {cluster_id} has too few documents. Using global model.\")\n",
        "                self.cluster_lda_models[cluster_id] = self.global_lda_model\n",
        "                self.cluster_vectorizers[cluster_id] = self.global_vectorizer\n",
        "                continue\n",
        "\n",
        "            # Cluster-specific vectorizer\n",
        "            vectorizer = CountVectorizer(max_df=0.85, min_df=2, stop_words='english',\n",
        "                                         ngram_range=(1, 2), max_features=500)\n",
        "            dtm = vectorizer.fit_transform(cluster_docs)\n",
        "\n",
        "            # Train LDA\n",
        "            lda = LatentDirichletAllocation(\n",
        "                n_components=1,  # Each cluster gets one primary topic\n",
        "                learning_method='online',\n",
        "                random_state=42,\n",
        "                max_iter=10\n",
        "            )\n",
        "            lda.fit(dtm)\n",
        "\n",
        "            self.cluster_lda_models[cluster_id] = lda\n",
        "            self.cluster_vectorizers[cluster_id] = vectorizer\n",
        "\n",
        "    def compute_topic_embeddings(self, documents):\n",
        "        \"\"\"Optimized topic embedding calculation with adaptive topic count and MMR diversification\"\"\"\n",
        "        # Get BERT embeddings and reduce dimensions\n",
        "        bert_embeddings = self.bert_model.encode(documents)\n",
        "        reduced_embeddings = self.reduce_dimensions(bert_embeddings)\n",
        "\n",
        "        # Cluster documents using HDBSCAN or KMeans\n",
        "        if HDBSCAN_AVAILABLE:\n",
        "            try:\n",
        "                cluster_model = HDBSCAN(min_cluster_size=10, gen_min_span_tree=True)\n",
        "                clusters = cluster_model.fit_predict(reduced_embeddings)\n",
        "                n_clusters = len(np.unique(clusters)) - (1 if -1 in clusters else 0)\n",
        "                self.n_topics = max(3, min(n_clusters, 10))\n",
        "                self.cluster_model = cluster_model\n",
        "                self.clusters = clusters\n",
        "                print(f\"HDBSCAN found {n_clusters} clusters\")\n",
        "            except Exception as e:\n",
        "                print(f\"HDBSCAN failed: {str(e)}. Using KMeans.\")\n",
        "                self._cluster_with_kmeans(reduced_embeddings)\n",
        "        else:\n",
        "            self._cluster_with_kmeans(reduced_embeddings)\n",
        "\n",
        "        # Adaptive topic count optimization using coherence\n",
        "        best_coherence = float('-inf')  # Initialize to negative infinity\n",
        "        best_lda = None\n",
        "        best_vectorizer = None\n",
        "        optimal_topics = self.n_topics  # Initialize with current cluster count\n",
        "\n",
        "        # Define topic range safely\n",
        "        min_topics = max(2, self.n_topics - 2)\n",
        "        max_topics = min(self.n_topics + 3, 15)\n",
        "        topic_range = range(min_topics, max_topics + 1)\n",
        "\n",
        "        print(f\"Optimizing LDA topic count in range {list(topic_range)}...\")\n",
        "        for n in topic_range:\n",
        "            # Train temporary LDA model\n",
        "            academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section',\n",
        "                                   'example', 'problem', 'solution', 'study', 'learn']\n",
        "            vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english',\n",
        "                                         ngram_range=(1, 2), max_features=1000)\n",
        "            vectorizer.stop_words_ = set(list(vectorizer.get_stop_words()) + academic_stop_words)\n",
        "            dtm = vectorizer.fit_transform(documents)\n",
        "\n",
        "            lda = LatentDirichletAllocation(\n",
        "                n_components=n,\n",
        "                learning_method='online',\n",
        "                random_state=42,\n",
        "                max_iter=10\n",
        "            )\n",
        "            lda.fit(dtm)\n",
        "\n",
        "            # Calculate coherence\n",
        "            coherence = self.calculate_coherence(lda, vectorizer, documents)\n",
        "            print(f\"  Topics={n} | Coherence={coherence:.3f}\")\n",
        "\n",
        "            if coherence > best_coherence:\n",
        "                best_coherence = coherence\n",
        "                best_lda = lda\n",
        "                best_vectorizer = vectorizer\n",
        "                optimal_topics = n  # Update optimal topic count\n",
        "\n",
        "        # Set best models\n",
        "        self.global_lda_model = best_lda\n",
        "        self.global_vectorizer = best_vectorizer\n",
        "        print(f\"Selected LDA model with {optimal_topics} topics (Coherence={best_coherence:.3f})\")\n",
        "\n",
        "        # Create enhanced topic embeddings with MMR diversification\n",
        "        self.topic_embeddings = []\n",
        "        unique_clusters = np.unique(self.clusters)\n",
        "\n",
        "        for cluster_id in unique_clusters:\n",
        "            if cluster_id == -1:\n",
        "                continue  # Skip noise points\n",
        "\n",
        "            # Get cluster documents\n",
        "            cluster_mask = (self.clusters == cluster_id)\n",
        "            cluster_docs = [doc for i, doc in enumerate(documents) if cluster_mask[i]]\n",
        "\n",
        "            # Get cluster centroid\n",
        "            cluster_embeddings = bert_embeddings[cluster_mask]\n",
        "            centroid = np.mean(cluster_embeddings, axis=0) if len(cluster_embeddings) > 0 else np.mean(bert_embeddings,\n",
        "                                                                                                       axis=0)\n",
        "\n",
        "            # Get candidate terms using TF-IDF\n",
        "            if cluster_docs:\n",
        "                try:\n",
        "                    # Get top candidate terms from cluster documents\n",
        "                    candidate_terms = self.get_candidate_terms(cluster_docs)\n",
        "\n",
        "                    # Apply MMR diversification\n",
        "                    selected_terms = self.mmr_diversification(\n",
        "                        centroid,\n",
        "                        candidate_terms,\n",
        "                        self.bert_model,\n",
        "                        diversity_factor=0.7,\n",
        "                        top_n=15\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(f\"Term selection failed for cluster {cluster_id}: {str(e)}\")\n",
        "                    selected_terms = self._get_global_topic_words(cluster_id)\n",
        "            else:\n",
        "                selected_terms = self._get_global_topic_words(cluster_id)\n",
        "\n",
        "            # Encode selected terms\n",
        "            if selected_terms:\n",
        "                try:\n",
        "                    word_embeddings = self.bert_model.encode(selected_terms)\n",
        "                    word_avg = np.mean(word_embeddings, axis=0)\n",
        "                except:\n",
        "                    word_avg = centroid\n",
        "            else:\n",
        "                word_avg = centroid\n",
        "\n",
        "            # Combine embeddings\n",
        "            combined_embedding = 0.85 * centroid + 0.15 * word_avg\n",
        "            self.topic_embeddings.append(combined_embedding)\n",
        "\n",
        "        self.topic_embeddings = np.array(self.topic_embeddings)\n",
        "        return self.topic_embeddings\n",
        "\n",
        "    def _cluster_with_kmeans(self, reduced_embeddings):\n",
        "        \"\"\"Cluster using KMeans as fallback\"\"\"\n",
        "        self.cluster_model = KMeans(n_clusters=self.n_topics, random_state=42)\n",
        "        self.clusters = self.cluster_model.fit_predict(reduced_embeddings)\n",
        "        print(f\"Using KMeans with {self.n_topics} clusters\")\n",
        "\n",
        "    def _get_global_topic_words(self, cluster_id):\n",
        "        \"\"\"Get top words from global LDA\"\"\"\n",
        "        cluster_idx = min(cluster_id, self.global_lda_model.components_.shape[0]-1)\n",
        "        top_indices = self.global_lda_model.components_[cluster_idx].argsort()[::-1][:20]\n",
        "        return [self.global_vectorizer.get_feature_names_out()[i] for i in top_indices]\n",
        "\n",
        "    def get_document_topic_distribution(self, documents):\n",
        "        \"\"\"Improved distribution using semantic similarity with contextual weighting\"\"\"\n",
        "        doc_embeddings = self.bert_model.encode(documents)\n",
        "        semantic_sim = cosine_similarity(doc_embeddings, self.topic_embeddings)\n",
        "\n",
        "        # Get cluster probabilities\n",
        "        reduced_embeddings = self.reducer.transform(doc_embeddings)\n",
        "        cluster_probs = self._get_cluster_probabilities(reduced_embeddings)\n",
        "\n",
        "        # Combine with contextual weighting\n",
        "        hybrid_dist = 0.75 * semantic_sim + 0.25 * cluster_probs\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        temperature = 0.7\n",
        "        scaled_dist = np.exp(hybrid_dist / temperature)\n",
        "        return scaled_dist / np.sum(scaled_dist, axis=1, keepdims=True)\n",
        "\n",
        "    def _get_cluster_probabilities(self, embeddings):\n",
        "        \"\"\"Get soft cluster probabilities\"\"\"\n",
        "        if hasattr(self.cluster_model, 'predict_proba'):\n",
        "            return self.cluster_model.predict_proba(embeddings)\n",
        "        else:\n",
        "            # Create soft clustering for KMeans\n",
        "            distances = self.cluster_model.transform(embeddings)\n",
        "            return 1 / (1 + distances)\n",
        "\n",
        "    def get_dominant_topic(self, documents):\n",
        "        \"\"\"Extract dominant topic\"\"\"\n",
        "        hybrid_dist = self.get_document_topic_distribution(documents)\n",
        "        return np.argmax(hybrid_dist, axis=1)\n",
        "\n",
        "    # Helper methods needed in the class:\n",
        "    def calculate_coherence(self, lda_model, vectorizer, documents):\n",
        "        \"\"\"Calculate topic coherence using UMass measure with sparse matrix support\"\"\"\n",
        "        # Get topic terms\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        topics = []\n",
        "        for topic_idx in range(lda_model.n_components):\n",
        "            top_indices = lda_model.components_[topic_idx].argsort()[::-1][:10]\n",
        "            topics.append([feature_names[i] for i in top_indices])\n",
        "\n",
        "        # Prepare document-term matrix\n",
        "        dtm = vectorizer.transform(documents)\n",
        "\n",
        "        # Calculate pairwise coherence\n",
        "        total_coherence = 0\n",
        "        valid_topics = 0\n",
        "\n",
        "        for topic in topics:\n",
        "            topic_coherence = 0\n",
        "            valid_pairs = 0\n",
        "\n",
        "            for i in range(1, len(topic)):\n",
        "                for j in range(0, i):\n",
        "                    # Get vocabulary indices\n",
        "                    try:\n",
        "                        idx_i = vectorizer.vocabulary_[topic[j]]\n",
        "                        idx_j = vectorizer.vocabulary_[topic[i]]\n",
        "                    except KeyError:\n",
        "                        continue\n",
        "\n",
        "                    # Get co-occurrence statistics using sparse matrix operations\n",
        "                    # Count documents containing term i\n",
        "                    D_wi = (dtm[:, idx_i] != 0).sum()\n",
        "\n",
        "                    # Count documents containing both terms i and j\n",
        "                    # Create binary masks for each term\n",
        "                    term_i_mask = (dtm[:, idx_i] != 0).astype(int)\n",
        "                    term_j_mask = (dtm[:, idx_j] != 0).astype(int)\n",
        "\n",
        "                    # Calculate co-occurrence using dot product\n",
        "                    D_wi_wj = term_i_mask.multiply(term_j_mask).sum()\n",
        "\n",
        "                    # Avoid division by zero\n",
        "                    if D_wi > 0 and D_wi_wj > 0:\n",
        "                        score = np.log((D_wi_wj + 1.0) / D_wi)\n",
        "                        topic_coherence += score\n",
        "                        valid_pairs += 1\n",
        "\n",
        "            # Only count topics with valid pairs\n",
        "            if valid_pairs > 0:\n",
        "                total_coherence += topic_coherence / valid_pairs\n",
        "                valid_topics += 1\n",
        "\n",
        "        # Return average coherence across valid topics\n",
        "        return total_coherence / valid_topics if valid_topics > 0 else 0\n",
        "\n",
        "    def get_candidate_terms(self, cluster_docs, top_n=100):\n",
        "        \"\"\"Get top candidate terms from cluster documents using TF-IDF\"\"\"\n",
        "        vectorizer = TfidfVectorizer(max_features=top_n, stop_words='english')\n",
        "        try:\n",
        "            tfidf = vectorizer.fit_transform(cluster_docs)\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "            word_scores = tfidf.sum(axis=0).A1\n",
        "            top_indices = word_scores.argsort()[::-1][:top_n]\n",
        "            return [feature_names[i] for i in top_indices]\n",
        "        except ValueError:\n",
        "            return []\n",
        "\n",
        "    def mmr_diversification(self, centroid, terms, bert_model, diversity_factor=0.7, top_n=15):\n",
        "        \"\"\"Maximal Marginal Relevance for diverse term selection\"\"\"\n",
        "        if not terms:\n",
        "            return []\n",
        "\n",
        "        # Encode all terms at once\n",
        "        term_embeddings = bert_model.encode(terms)\n",
        "\n",
        "        # Calculate similarity to centroid\n",
        "        centroid_sim = cosine_similarity([centroid], term_embeddings)[0]\n",
        "\n",
        "        selected_indices = []\n",
        "        selected_terms = []\n",
        "\n",
        "        # Start with most relevant term\n",
        "        first_idx = np.argmax(centroid_sim)\n",
        "        selected_indices.append(first_idx)\n",
        "        selected_terms.append(terms[first_idx])\n",
        "\n",
        "        # Iteratively select remaining terms\n",
        "        while len(selected_terms) < min(top_n, len(terms)):\n",
        "            candidate_indices = set(range(len(terms))) - set(selected_indices)\n",
        "            if not candidate_indices:\n",
        "                break\n",
        "\n",
        "            mmr_scores = []\n",
        "            for idx in candidate_indices:\n",
        "                # Relevance to centroid\n",
        "                rel_score = centroid_sim[idx]\n",
        "\n",
        "                # Max similarity to selected terms\n",
        "                max_sim = 0\n",
        "                if selected_indices:\n",
        "                    sims = cosine_similarity(\n",
        "                        [term_embeddings[idx]],\n",
        "                        [term_embeddings[i] for i in selected_indices]\n",
        "                    )\n",
        "                    max_sim = np.max(sims)\n",
        "\n",
        "                # MMR calculation\n",
        "                mmr = diversity_factor * rel_score - (1 - diversity_factor) * max_sim\n",
        "                mmr_scores.append((idx, mmr))\n",
        "\n",
        "            # Select term with highest MMR\n",
        "            next_idx = max(mmr_scores, key=lambda x: x[1])[0]\n",
        "            selected_indices.append(next_idx)\n",
        "            selected_terms.append(terms[next_idx])\n",
        "\n",
        "        return selected_terms\n",
        "\n",
        "    def _get_cluster_probabilities(self, embeddings):\n",
        "        \"\"\"Robust cluster probability calculation for all clustering methods\"\"\"\n",
        "        # 1. Models with predict_proba method\n",
        "        if hasattr(self.cluster_model, 'predict_proba'):\n",
        "            try:\n",
        "                return self.cluster_model.predict_proba(embeddings)\n",
        "            except Exception as e:\n",
        "                print(f\"Predict_proba failed: {str(e)}. Using fallback.\")\n",
        "\n",
        "        # 2. HDBSCAN-specific handling\n",
        "        if HDBSCAN_AVAILABLE and isinstance(self.cluster_model, HDBSCAN):\n",
        "            try:\n",
        "                # Get soft clusters for HDBSCAN\n",
        "                return self.cluster_model.membership_vector(embeddings)\n",
        "            except Exception as e:\n",
        "                print(f\"HDBSCAN membership_vector failed: {str(e)}\")\n",
        "\n",
        "        # 3. KMeans/GMM fallback\n",
        "        if hasattr(self.cluster_model, 'transform'):\n",
        "            try:\n",
        "                # Soft clustering via distance transform\n",
        "                distances = self.cluster_model.transform(embeddings)\n",
        "                return 1 / (1 + distances)\n",
        "            except Exception as e:\n",
        "                print(f\"Distance transform failed: {str(e)}\")\n",
        "\n",
        "        # 4. Final fallback: one-hot encoding from labels\n",
        "        try:\n",
        "            labels = self.cluster_model.predict(embeddings)\n",
        "            n_clusters = len(np.unique(labels))\n",
        "            probs = np.zeros((len(embeddings), n_clusters))\n",
        "            probs[np.arange(len(embeddings)), labels] = 1\n",
        "            return probs\n",
        "        except Exception as e:\n",
        "            print(f\"One-hot encoding failed: {str(e)}\")\n",
        "            # Uniform distribution as last resort\n",
        "            return np.ones((len(embeddings), self.n_topics)) / self.n_topics\n",
        "\n",
        "# ========================\n",
        "# 2. TOPIC MODEL EVALUATION\n",
        "# ========================\n",
        "\n",
        "class TopicModelEvaluator:\n",
        "    \"\"\"Evaluates multiple topic models using coherence and diversity metrics\"\"\"\n",
        "\n",
        "    def __init__(self, documents, n_topics=5):\n",
        "        self.documents = documents\n",
        "        self.n_topics = n_topics\n",
        "        self.tokenized_docs = self._tokenize_documents(documents)\n",
        "        self.dictionary = self._create_dictionary() if GENSIM_AVAILABLE else None\n",
        "        self.visualizer = ResultVisualizer()  # Initialize visualizer here\n",
        "\n",
        "    def _tokenize_documents(self, documents):\n",
        "        \"\"\"Tokenize documents using nltk or fallback\"\"\"\n",
        "        try:\n",
        "            from nltk.tokenize import word_tokenize\n",
        "            return [word_tokenize(doc.lower()) for doc in documents]\n",
        "        except ImportError:\n",
        "            return [doc.lower().split() for doc in documents]\n",
        "\n",
        "    def _calculate_topic_quality(self, topics):\n",
        "        \"\"\"Robust topic quality calculation with comprehensive error handling\"\"\"\n",
        "        # Initialize default metrics\n",
        "        metrics = {\n",
        "            \"coherence\": 0.5,\n",
        "            \"distinctiveness\": 0.0,\n",
        "            \"relevance\": 0.0\n",
        "        }\n",
        "\n",
        "        # Validate topics input\n",
        "        if not topics or not isinstance(topics, list) or len(topics) == 0:\n",
        "            print(\"Warning: Invalid topics format. Returning default metrics.\")\n",
        "            return metrics\n",
        "\n",
        "        # 1. Topic coherence calculation\n",
        "        metrics[\"coherence\"] = self._calculate_coherence(topics)\n",
        "\n",
        "        # 2. Topic distinctiveness\n",
        "        try:\n",
        "            unique_words = set()\n",
        "            total_words = 0\n",
        "            for topic in topics:\n",
        "                if not topic:  # Skip empty topics\n",
        "                    continue\n",
        "                for word in topic:\n",
        "                    if word:  # Skip empty strings\n",
        "                        unique_words.add(word)\n",
        "                        total_words += 1\n",
        "            metrics[\"distinctiveness\"] = len(unique_words) / total_words if total_words > 0 else 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"Distinctiveness calculation failed: {str(e)}\")\n",
        "            metrics[\"distinctiveness\"] = 0.0\n",
        "\n",
        "        # 3. Term relevance (IDF-weighted)\n",
        "        try:\n",
        "            from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "            # Handle empty documents\n",
        "            if not self.documents or len(self.documents) == 0:\n",
        "                print(\"Warning: No documents for relevance calculation.\")\n",
        "                return metrics\n",
        "\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            try:\n",
        "                tfidf = vectorizer.fit_transform(self.documents)\n",
        "                idf = vectorizer.idf_\n",
        "                vocab = vectorizer.get_feature_names_out()\n",
        "            except ValueError:\n",
        "                # Fallback for small documents\n",
        "                print(\"Using fallback TF-IDF for small document set\")\n",
        "                vectorizer = TfidfVectorizer(min_df=1)\n",
        "                tfidf = vectorizer.fit_transform(self.documents)\n",
        "                idf = vectorizer.idf_\n",
        "                vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "            relevance_scores = []\n",
        "            for topic in topics:\n",
        "                if not topic:  # Skip empty topics\n",
        "                    continue\n",
        "\n",
        "                topic_score = 0.0\n",
        "                valid_terms = 0\n",
        "\n",
        "                for term in topic:\n",
        "                    if term and term in vocab:  # Check for non-empty term\n",
        "                        try:\n",
        "                            idx = np.where(vocab == term)[0][0]\n",
        "                            topic_score += idf[idx]\n",
        "                            valid_terms += 1\n",
        "                        except IndexError:\n",
        "                            pass\n",
        "\n",
        "                if valid_terms > 0:\n",
        "                    relevance_scores.append(topic_score / valid_terms)\n",
        "\n",
        "            metrics[\"relevance\"] = np.mean(relevance_scores) if relevance_scores else 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"Relevance calculation failed: {str(e)}\")\n",
        "            metrics[\"relevance\"] = 0.0\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _create_dictionary(self):\n",
        "        \"\"\"Create gensim dictionary with filtering\"\"\"\n",
        "        if not GENSIM_AVAILABLE:\n",
        "            return None\n",
        "        dictionary = Dictionary(self.tokenized_docs)\n",
        "        dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
        "        return dictionary\n",
        "\n",
        "    def _calculate_coherence(self, topics):\n",
        "        \"\"\"Reliable coherence calculation with multiple fallbacks\"\"\"\n",
        "        # Validate input\n",
        "        if not topics or any(len(t) == 0 for t in topics):\n",
        "            return 0.5\n",
        "\n",
        "        # Attempt c_v coherence\n",
        "        try:\n",
        "            dictionary = Dictionary(self.tokenized_docs)\n",
        "            dictionary.filter_extremes(no_below=3, no_above=0.8)\n",
        "            coherence_model = CoherenceModel(\n",
        "                topics=topics,\n",
        "                texts=self.tokenized_docs,\n",
        "                dictionary=dictionary,\n",
        "                coherence='c_v'\n",
        "            )\n",
        "            return max(0, min(1.0, coherence_model.get_coherence()))\n",
        "        except Exception as e:\n",
        "            print(f\"c_v coherence failed: {str(e)}\")\n",
        "\n",
        "        # Attempt u_mass coherence\n",
        "        try:\n",
        "            corpus = [dictionary.doc2bow(doc) for doc in self.tokenized_docs]\n",
        "            coherence_model = CoherenceModel(\n",
        "                topics=topics,\n",
        "                corpus=corpus,\n",
        "                dictionary=dictionary,\n",
        "                coherence='u_mass'\n",
        "            )\n",
        "            u_mass = coherence_model.get_coherence()\n",
        "            # Convert to 0-1 scale (approximate)\n",
        "            return min(1.0, max(0, (u_mass + 10) / 20))\n",
        "        except Exception as e:\n",
        "            print(f\"u_mass coherence failed: {str(e)}\")\n",
        "\n",
        "        # Fallback to simple metric\n",
        "        return self._simple_topic_coherence(topics)\n",
        "\n",
        "    def _simple_topic_coherence(self, topics):\n",
        "        \"\"\"Fallback coherence metric based on PMI\"\"\"\n",
        "        from itertools import combinations\n",
        "        from collections import defaultdict\n",
        "\n",
        "        # Create document frequency map\n",
        "        doc_freq = defaultdict(int)\n",
        "        cooc_freq = defaultdict(int)\n",
        "\n",
        "        for doc in self.tokenized_docs:\n",
        "            unique_words = set(doc)\n",
        "            for word in unique_words:\n",
        "                doc_freq[word] += 1\n",
        "            for w1, w2 in combinations(unique_words, 2):\n",
        "                cooc_freq[(w1, w2)] += 1\n",
        "\n",
        "        # Calculate average pairwise PMI\n",
        "        topic_coherence = []\n",
        "        for topic in topics:\n",
        "            topic = [word for word in topic if word in doc_freq]\n",
        "            if len(topic) < 2:\n",
        "                continue\n",
        "\n",
        "            pmi_scores = []\n",
        "            for (w1, w2) in combinations(topic, 2):\n",
        "                if (w1, w2) in cooc_freq:\n",
        "                    p_w1w2 = cooc_freq[(w1, w2)] / len(self.tokenized_docs)\n",
        "                    p_w1 = doc_freq[w1] / len(self.tokenized_docs)\n",
        "                    p_w2 = doc_freq[w2] / len(self.tokenized_docs)\n",
        "                    pmi = np.log(p_w1w2 / (p_w1 * p_w2))\n",
        "                    pmi_scores.append(pmi)\n",
        "\n",
        "            if pmi_scores:\n",
        "                topic_coherence.append(np.mean(pmi_scores))\n",
        "\n",
        "        # Normalize to 0-1 scale\n",
        "        if topic_coherence:\n",
        "            max_pmi = max(topic_coherence)\n",
        "            return min(1.0, max(0, np.mean(topic_coherence) / max_pmi if max_pmi > 0 else 0))\n",
        "        return 0.5\n",
        "\n",
        "    def _calculate_diversity(self, topics):\n",
        "        \"\"\"Calculate topic diversity metric\"\"\"\n",
        "        unique_words = set()\n",
        "        total_words = 0\n",
        "        for topic in topics:\n",
        "            for word in topic:\n",
        "                unique_words.add(word)\n",
        "                total_words += 1\n",
        "        return len(unique_words) / total_words if total_words > 0 else 0\n",
        "\n",
        "    def evaluate_hybrid_model(self, hybrid_model):\n",
        "        \"\"\"Enhanced evaluation for both hybrid models\"\"\"\n",
        "        enhanced_topics = []\n",
        "        n_topics = hybrid_model.n_topics\n",
        "\n",
        "        # Get topic terms based on model type\n",
        "        if hasattr(hybrid_model, 'global_vectorizer') and hybrid_model.global_vectorizer is not None:\n",
        "            # Enhanced hybrid model\n",
        "            feature_names = hybrid_model.global_vectorizer.get_feature_names_out()\n",
        "            top_indices = hybrid_model.global_lda_model.components_.argsort(axis=1)[:, ::-1][:, :10]\n",
        "        else:\n",
        "            # Original hybrid model\n",
        "            feature_names = hybrid_model.vectorizer.get_feature_names_out()\n",
        "            top_indices = hybrid_model.lda_model.components_.argsort(axis=1)[:, ::-1][:, :10]\n",
        "\n",
        "        topic_terms = [feature_names[i] for row in top_indices for i in row]\n",
        "\n",
        "        for i in range(n_topics):\n",
        "            # Slice terms for the current topic\n",
        "            start_idx = i * 10\n",
        "            end_idx = start_idx + 10\n",
        "            terms = topic_terms[start_idx:end_idx]\n",
        "\n",
        "            # Get topic embedding\n",
        "            topic_embedding = hybrid_model.topic_embeddings[i]\n",
        "\n",
        "            # Find representative documents\n",
        "            doc_embeddings = hybrid_model.bert_model.encode(self.documents)\n",
        "            doc_sims = cosine_similarity([topic_embedding], doc_embeddings)[0]\n",
        "            top_doc_idx = np.argsort(doc_sims)[-5:]  # Top 5 documents\n",
        "            top_docs = [self.documents[i] for i in top_doc_idx]\n",
        "\n",
        "            # Extract meaningful nouns\n",
        "            nouns = [w for doc in top_docs for w in doc.split() if len(w) > 3 and w.isalpha()]\n",
        "            counter = Counter(nouns)\n",
        "\n",
        "            # Add new relevant terms\n",
        "            terms_list = list(terms)\n",
        "            new_terms = [word for word, _ in counter.most_common(3) if word not in terms_list]\n",
        "\n",
        "            if not new_terms:\n",
        "                enhanced_terms = terms[:7]  # Use top 7 terms if no new terms\n",
        "            else:\n",
        "                padded_new_terms = new_terms[:3] + [''] * (3 - len(new_terms))\n",
        "                enhanced_terms = terms[:7] + padded_new_terms[:3]\n",
        "\n",
        "            enhanced_topics.append(enhanced_terms)\n",
        "\n",
        "        return enhanced_topics\n",
        "\n",
        "    def evaluate_enhanced_hybrid_model(self, hybrid_model):\n",
        "        \"\"\"Evaluation specifically for the paper-inspired hybrid model\"\"\"\n",
        "        topics = []\n",
        "        n_topics = hybrid_model.n_topics\n",
        "\n",
        "        # Get top words from global LDA\n",
        "        feature_names = hybrid_model.global_vectorizer.get_feature_names_out()\n",
        "\n",
        "        for i in range(n_topics):\n",
        "            top_indices = hybrid_model.global_lda_model.components_[i].argsort()[::-1][:10]\n",
        "            topics.append([feature_names[idx] for idx in top_indices])\n",
        "\n",
        "        return topics\n",
        "\n",
        "    def evaluate_bert_model(self, documents):\n",
        "        \"\"\"Evaluate BERT-based topic modeling\"\"\"\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        embeddings = model.encode(documents)\n",
        "        kmeans = KMeans(n_clusters=self.n_topics, random_state=42)\n",
        "        clusters = kmeans.fit_predict(embeddings)\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "        vectorizer.fit(documents)\n",
        "        vocabulary = vectorizer.get_feature_names_out()\n",
        "        topics = []\n",
        "        for i in range(self.n_topics):\n",
        "            cluster_docs = [documents[j] for j in range(len(documents)) if clusters[j] == i]\n",
        "            if not cluster_docs:\n",
        "                topics.append([])\n",
        "                continue\n",
        "            cluster_tfidf = vectorizer.transform(cluster_docs)\n",
        "            word_scores = cluster_tfidf.sum(axis=0).A1\n",
        "            top_indices = word_scores.argsort()[-10:][::-1]\n",
        "            topics.append([vocabulary[idx] for idx in top_indices])\n",
        "        return topics\n",
        "\n",
        "    def train_global_lda(self, documents):\n",
        "        \"\"\"Train global LDA model as fallback\"\"\"\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section',\n",
        "                               'example', 'problem', 'solution', 'study', 'learn']\n",
        "        self.global_vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english',\n",
        "                                                 ngram_range=(1, 2), max_features=1000)\n",
        "        self.global_vectorizer.stop_words_ = set(list(self.global_vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.global_vectorizer.fit_transform(documents)\n",
        "\n",
        "        self.global_lda_model = LatentDirichletAllocation(\n",
        "            n_components=self.n_topics,\n",
        "            random_state=42,\n",
        "            max_iter=15\n",
        "        )\n",
        "        self.global_lda_model.fit(dtm)\n",
        "        return self.global_lda_model\n",
        "\n",
        "    def train_lda_per_cluster(self, documents, clusters):\n",
        "        \"\"\"Train separate LDA models for each cluster\"\"\"\n",
        "        for cluster_id in range(self.n_topics):\n",
        "            cluster_docs = [doc for i, doc in enumerate(documents) if clusters[i] == cluster_id]\n",
        "\n",
        "            if len(cluster_docs) < 10:  # Minimum documents threshold\n",
        "                print(f\"Cluster {cluster_id} has too few documents. Using global model.\")\n",
        "                self.cluster_lda_models[cluster_id] = self.global_lda_model\n",
        "                self.cluster_vectorizers[cluster_id] = self.global_vectorizer\n",
        "                continue\n",
        "\n",
        "            # Cluster-specific vectorizer\n",
        "            vectorizer = CountVectorizer(max_df=0.85, min_df=2, stop_words='english',\n",
        "                                         ngram_range=(1, 2), max_features=500)\n",
        "            dtm = vectorizer.fit_transform(cluster_docs)\n",
        "\n",
        "            # Train LDA\n",
        "            lda = LatentDirichletAllocation(\n",
        "                n_components=1,  # Each cluster gets one primary topic\n",
        "                learning_method='online',\n",
        "                random_state=42,\n",
        "                max_iter=10\n",
        "            )\n",
        "            lda.fit(dtm)\n",
        "\n",
        "            self.cluster_lda_models[cluster_id] = lda\n",
        "            self.cluster_vectorizers[cluster_id] = vectorizer\n",
        "\n",
        "\n",
        "    def train_lda(self, documents):\n",
        "        # FIXED: Properly handle NumPy arrays\n",
        "        if documents is None or len(documents) == 0:\n",
        "            print(\"Warning: No documents for LDA training. Using default model.\")\n",
        "            self.lda_model = LatentDirichletAllocation(n_components=self.n_topics, random_state=42)\n",
        "            return\n",
        "\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section', 'example', 'problem', 'solution', 'study', 'learn']\n",
        "        self.vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english', ngram_range=(1, 2), max_features=1000)\n",
        "        self.vectorizer.stop_words_ = set(list(self.vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.vectorizer.fit_transform(documents)\n",
        "\n",
        "        if GENSIM_AVAILABLE:\n",
        "            best_coherence = -1\n",
        "            for alpha in [0.1, 0.5, 1.0]:\n",
        "                for eta in [0.01, 0.1]:\n",
        "                    lda = LatentDirichletAllocation(\n",
        "                        n_components=self.n_topics,\n",
        "                        learning_method='online',\n",
        "                        learning_offset=10.,\n",
        "                        random_state=42,\n",
        "                        max_iter=15,\n",
        "                        n_jobs=-1,\n",
        "                        doc_topic_prior=alpha,\n",
        "                        topic_word_prior=eta\n",
        "                    )\n",
        "                    lda.fit(dtm)\n",
        "                    # Extract topics manually for CoherenceModel\n",
        "                    feature_names = self.vectorizer.get_feature_names_out()\n",
        "                    topics = [[feature_names[i] for i in topic.argsort()[:-11:-1]] for topic in lda.components_]\n",
        "                    coherence_model = CoherenceModel(\n",
        "                        topics=topics,\n",
        "                        texts=[doc.split() for doc in documents],\n",
        "                        dictionary=Dictionary([doc.split() for doc in documents]),\n",
        "                        coherence='c_v'\n",
        "                    )\n",
        "                    coherence = coherence_model.get_coherence()\n",
        "                    if coherence > best_coherence:\n",
        "                        best_coherence = coherence\n",
        "                        self.lda_model = lda\n",
        "        else:\n",
        "            print(\"Gensim not available. Using default LDA model.\")\n",
        "            self.lda_model = LatentDirichletAllocation(\n",
        "                n_components=self.n_topics,\n",
        "                random_state=42,\n",
        "                max_iter=15,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            self.lda_model.fit(dtm)\n",
        "\n",
        "        # FIXED TOPIC TERM GENERATION\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "        top_indices = self.lda_model.components_.argsort(axis=1)[:, ::-1][:, :10]\n",
        "        self.topic_terms = [feature_names[i] for row in top_indices for i in row]\n",
        "\n",
        "    def compute_topic_embeddings(self, documents):\n",
        "        \"\"\"Enhanced topic embeddings combining cluster, BERT, and LDA information\"\"\"\n",
        "        # Get BERT embeddings and reduce dimensions\n",
        "        bert_embeddings = self.bert_model.encode(documents)\n",
        "        reduced_embeddings = self.reduce_dimensions(bert_embeddings)\n",
        "\n",
        "        # Cluster documents\n",
        "        clusters = self.cluster_documents(reduced_embeddings)\n",
        "\n",
        "        # Train global LDA as fallback\n",
        "        self.train_global_lda(documents)\n",
        "\n",
        "        # Train cluster-specific LDA models\n",
        "        self.train_lda_per_cluster(documents, clusters)\n",
        "\n",
        "        # Create unified topic embeddings\n",
        "        self.topic_embeddings = []\n",
        "        for cluster_id in range(self.n_topics):\n",
        "            # Get cluster centroid\n",
        "            cluster_mask = (clusters == cluster_id)\n",
        "            cluster_center = np.mean(bert_embeddings[cluster_mask], axis=0) if any(cluster_mask) else np.mean(\n",
        "                bert_embeddings, axis=0)\n",
        "\n",
        "            # Get top words from cluster-specific LDA\n",
        "            lda = self.cluster_lda_models[cluster_id]\n",
        "            vectorizer = self.cluster_vectorizers[cluster_id]\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "            if lda.components_.shape[0] > 0:\n",
        "                top_words_idx = lda.components_[0].argsort()[::-1][:10]\n",
        "                top_words = [feature_names[i] for i in top_words_idx]\n",
        "            else:\n",
        "                # Fallback to global model\n",
        "                top_words_idx = self.global_lda_model.components_[cluster_id].argsort()[::-1][:10]\n",
        "                top_words = [self.global_vectorizer.get_feature_names_out()[i] for i in top_words_idx]\n",
        "\n",
        "            # Encode top words\n",
        "            word_embeddings = self.bert_model.encode(top_words)\n",
        "            word_avg = np.mean(word_embeddings, axis=0)\n",
        "\n",
        "            # Combine embeddings\n",
        "            combined_embedding = (self.lambda_weight * cluster_center +\n",
        "                                  (1 - self.lambda_weight) * word_avg)\n",
        "            self.topic_embeddings.append(combined_embedding)\n",
        "\n",
        "        self.topic_embeddings = np.array(self.topic_embeddings)\n",
        "\n",
        "    def evaluate_lda_model(self, documents):\n",
        "        \"\"\"Train LDA model and extract topics for evaluation\"\"\"\n",
        "        # Train LDA using existing method\n",
        "        self.train_lda(documents)\n",
        "\n",
        "        # Extract topics from trained model\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "        topics = []\n",
        "        for topic_idx in range(self.lda_model.components_.shape[0]):\n",
        "            top_indices = self.lda_model.components_[topic_idx].argsort()[::-1][:10]\n",
        "            topics.append([feature_names[i] for i in top_indices])\n",
        "        return topics\n",
        "\n",
        "    def run_evaluation(self, hybrid_model):\n",
        "        \"\"\"Run evaluation with enhanced hybrid model\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Evaluate our enhanced hybrid model\n",
        "        if isinstance(hybrid_model, EnhancedHybridTopicModel):\n",
        "            hybrid_topics = self.evaluate_enhanced_hybrid_model(hybrid_model)\n",
        "        else:\n",
        "            hybrid_topics = self.evaluate_hybrid_model(hybrid_model)\n",
        "\n",
        "        lda_topics = self.evaluate_lda_model(self.documents)\n",
        "        bert_topics = self.evaluate_bert_model(self.documents)\n",
        "\n",
        "        results[\"Hybrid (Ours)\"] = {\"topics\": hybrid_topics, \"metrics\": self._calculate_topic_quality(hybrid_topics)}\n",
        "        results[\"LDA Only\"] = {\"topics\": lda_topics, \"metrics\": self._calculate_topic_quality(lda_topics)}\n",
        "        results[\"BERT Only\"] = {\"topics\": bert_topics, \"metrics\": self._calculate_topic_quality(bert_topics)}\n",
        "\n",
        "        return results\n",
        "\n",
        "    def select_best_model(self, results):\n",
        "        \"\"\"Robust model selection with comprehensive error handling\"\"\"\n",
        "        best_model = None\n",
        "        best_score = -1\n",
        "        best_topics = None\n",
        "\n",
        "        # Default weights\n",
        "        weights = {\n",
        "            \"coherence\": 0.5,\n",
        "            \"distinctiveness\": 0.3,\n",
        "            \"relevance\": 0.2\n",
        "        }\n",
        "\n",
        "        for name, data in results.items():\n",
        "            # Skip models with missing data\n",
        "            if data is None or \"metrics\" not in data or data[\"metrics\"] is None:\n",
        "                print(f\"Warning: Missing metrics for {name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            metrics = data[\"metrics\"]\n",
        "            if metrics is None:\n",
        "                print(f\"Warning: Metrics are None for {name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Calculate score with fallbacks\n",
        "            try:\n",
        "                score = 0\n",
        "                for metric, weight in weights.items():\n",
        "                    value = metrics.get(metric, 0)\n",
        "                    score += weight * value\n",
        "            except Exception as e:\n",
        "                print(f\"Score calculation failed for {name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_model = name\n",
        "                best_topics = data.get(\"topics\", [])\n",
        "\n",
        "        if best_model is None:\n",
        "            print(\"Error: No valid models found. Using first model as fallback.\")\n",
        "            first_model = next(iter(results.keys()))\n",
        "            return first_model, results[first_model].get(\"topics\", [])\n",
        "\n",
        "        print(f\"Selected best model: {best_model} (Score: {best_score:.3f})\")\n",
        "        return best_model, best_topics\n",
        "\n",
        "    def visualize_results(self, results, filename=\"topic_model_comparison.png\"):\n",
        "        \"\"\"Robust visualization with comprehensive error handling\"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        import numpy as np\n",
        "\n",
        "        # Validate input results\n",
        "        if not results or not isinstance(results, dict):\n",
        "            print(\"Error: Invalid results format. Cannot visualize.\")\n",
        "            return\n",
        "\n",
        "        # Filter out invalid models\n",
        "        valid_models = []\n",
        "        metric_values = {m: {} for m in results}\n",
        "\n",
        "        metrics = [\"coherence\", \"distinctiveness\", \"relevance\"]\n",
        "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "\n",
        "        # Collect valid data with fallbacks\n",
        "        for model_name, model_data in results.items():\n",
        "            if model_data is None:\n",
        "                print(f\"Warning: Missing data for {model_name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            if \"metrics\" not in model_data:\n",
        "                print(f\"Warning: Missing metrics for {model_name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            model_metrics = model_data[\"metrics\"]\n",
        "            if model_metrics is None:\n",
        "                print(f\"Warning: Metrics are None for {model_name}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            valid_models.append(model_name)\n",
        "            for metric in metrics:\n",
        "                # Use 0 as fallback for missing metrics\n",
        "                value = model_metrics.get(metric, 0) if model_metrics else 0\n",
        "                metric_values[model_name][metric] = value\n",
        "\n",
        "        if not valid_models:\n",
        "            print(\"Error: No valid models with metrics to visualize.\")\n",
        "            return\n",
        "\n",
        "        # Create visualization\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        bar_width = 0.25\n",
        "        index = np.arange(len(valid_models))\n",
        "\n",
        "        for i, metric in enumerate(metrics):\n",
        "            values = [metric_values[m].get(metric, 0) for m in valid_models]\n",
        "            ax.bar(index + i * bar_width, values, bar_width,\n",
        "                   label=metric.capitalize(), color=colors[i])\n",
        "\n",
        "        ax.set_xlabel('Models')\n",
        "        ax.set_ylabel('Scores')\n",
        "        ax.set_title('Topic Model Quality Metrics')\n",
        "        ax.set_xticks(index + bar_width)\n",
        "        ax.set_xticklabels(valid_models)\n",
        "        ax.legend()\n",
        "        ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def comprehensive_evaluation(self, models_dict):\n",
        "        \"\"\"\n",
        "        Perform comprehensive evaluation of multiple models\n",
        "        models_dict: {'Model Name': model_instance}\n",
        "        Returns detailed comparison report\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        comparison_data = []\n",
        "\n",
        "        for model_name, model in models_dict.items():\n",
        "            print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "            # Get topics\n",
        "            if model_name == \"LDA Only\":\n",
        "                topics = self.evaluate_lda_model(self.documents)\n",
        "            elif model_name == \"BERT Only\":\n",
        "                topics = self.evaluate_bert_model(self.documents)\n",
        "            else:\n",
        "                topics = self.evaluate_hybrid_model(model) if not isinstance(model,\n",
        "                                                                             EnhancedHybridTopicModel) else self.evaluate_enhanced_hybrid_model(\n",
        "                    model)\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = self._calculate_topic_quality(topics)\n",
        "\n",
        "            # Store results\n",
        "            results[model_name] = {\n",
        "                \"topics\": topics,\n",
        "                \"metrics\": metrics\n",
        "            }\n",
        "\n",
        "            # Prepare for detailed comparison\n",
        "            comparison_data.append({\n",
        "                \"Model\": model_name,\n",
        "                \"Coherence\": metrics[\"coherence\"],\n",
        "                \"Distinctiveness\": metrics[\"distinctiveness\"],\n",
        "                \"Relevance\": metrics[\"relevance\"],\n",
        "                \"Overall Score\": 0.5 * metrics[\"coherence\"] + 0.3 * metrics[\"distinctiveness\"] + 0.2 * metrics[\n",
        "                    \"relevance\"]\n",
        "            })\n",
        "\n",
        "            # Print topic samples\n",
        "            print(f\"{model_name} Topics (Sample):\")\n",
        "            for i, topic in enumerate(topics[:3]):  # Show first 3 topics\n",
        "                print(f\"  Topic {i + 1}: {', '.join(topic[:5])}...\")\n",
        "\n",
        "        # Create comparison dataframe\n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        comparison_df = comparison_df.sort_values(\"Overall Score\", ascending=False)\n",
        "\n",
        "        # Visualize comparison\n",
        "        self.visualize_comparison(comparison_df)\n",
        "\n",
        "        # Generate detailed report\n",
        "        report = self.generate_comparison_report(comparison_df, results)\n",
        "\n",
        "        return comparison_df, report\n",
        "\n",
        "    def visualize_comparison(self, comparison_df):\n",
        "        \"\"\"Create comprehensive visualizations of model comparison\"\"\"\n",
        "        # Metrics comparison\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        metrics = [\"Coherence\", \"Distinctiveness\", \"Relevance\", \"Overall Score\"]\n",
        "\n",
        "        for i, metric in enumerate(metrics):\n",
        "            plt.subplot(2, 2, i + 1)\n",
        "            sns.barplot(x=\"Model\", y=metric, data=comparison_df.sort_values(metric, ascending=False),\n",
        "                        palette=\"viridis\")\n",
        "            plt.title(f\"{metric} Comparison\")\n",
        "            plt.xticks(rotation=15)\n",
        "            plt.tight_layout()\n",
        "\n",
        "        plt.savefig(\"model_metrics_comparison.png\", dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        # Radar chart\n",
        "        self.visualizer.plot_radar_chart(comparison_df)\n",
        "\n",
        "        # Topic quality scatter plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.scatterplot(\n",
        "            x=\"Coherence\",\n",
        "            y=\"Distinctiveness\",\n",
        "            size=\"Overall Score\",\n",
        "            hue=\"Model\",\n",
        "            data=comparison_df,\n",
        "            s=200,\n",
        "            alpha=0.8\n",
        "        )\n",
        "        plt.title(\"Topic Quality Comparison\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.savefig(\"topic_quality_scatter.png\", dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    def generate_comparison_report(self, comparison_df, results):\n",
        "        \"\"\"Generate detailed textual report of model comparison\"\"\"\n",
        "        report_lines = [\n",
        "            \"=\" * 70,\n",
        "            \"TOPIC MODELING PERFORMANCE COMPARISON REPORT\",\n",
        "            \"=\" * 70,\n",
        "            f\"Evaluated on {len(self.documents)} documents\",\n",
        "            f\"Number of topics: {self.n_topics}\",\n",
        "            \"-\" * 70,\n",
        "            \"Overall Ranking:\"\n",
        "        ]\n",
        "\n",
        "        # Ranking\n",
        "        for i, row in comparison_df.iterrows():\n",
        "            report_lines.append(f\"{i + 1}. {row['Model']}: {row['Overall Score']:.3f}\")\n",
        "\n",
        "        # Detailed comparison\n",
        "        report_lines.extend([\n",
        "            \"\\n\" + \"-\" * 70,\n",
        "            \"Detailed Metrics:\",\n",
        "            \"{:<20} {:<12} {:<15} {:<12} {:<12}\".format(\n",
        "                \"Model\", \"Coherence\", \"Distinctiveness\", \"Relevance\", \"Overall\"\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        for _, row in comparison_df.iterrows():\n",
        "            report_lines.append(\"{:<20} {:<12.3f} {:<15.3f} {:<12.3f} {:<12.3f}\".format(\n",
        "                row[\"Model\"], row[\"Coherence\"], row[\"Distinctiveness\"],\n",
        "                row[\"Relevance\"], row[\"Overall Score\"]\n",
        "            ))\n",
        "\n",
        "        # Performance insights\n",
        "        best_model = comparison_df.iloc[0][\"Model\"]\n",
        "        report_lines.extend([\n",
        "            \"\\n\" + \"-\" * 70,\n",
        "            \"Performance Insights:\",\n",
        "            f\"- Best performing model: {best_model}\",\n",
        "            f\"- Coherence range: {comparison_df['Coherence'].min():.3f} - {comparison_df['Coherence'].max():.3f}\",\n",
        "            f\"- Distinctiveness range: {comparison_df['Distinctiveness'].min():.3f} - {comparison_df['Distinctiveness'].max():.3f}\",\n",
        "            f\"- Relevance range: {comparison_df['Relevance'].min():.3f} - {comparison_df['Relevance'].max():.3f}\",\n",
        "            \"-\" * 70\n",
        "        ])\n",
        "\n",
        "        # Recommendations\n",
        "        report_lines.extend([\n",
        "            \"\\nRecommendations:\",\n",
        "            f\"- For coherence-focused applications: Use {comparison_df.sort_values('Coherence', ascending=False).iloc[0]['Model']}\",\n",
        "            f\"- For diverse topics: Use {comparison_df.sort_values('Distinctiveness', ascending=False).iloc[0]['Model']}\",\n",
        "            f\"- For relevant terms: Use {comparison_df.sort_values('Relevance', ascending=False).iloc[0]['Model']}\",\n",
        "            f\"- Overall best model: {best_model}\",\n",
        "            \"=\" * 70\n",
        "        ])\n",
        "\n",
        "        return \"\\n\".join(report_lines)\n",
        "\n",
        "\n",
        "# =============================\n",
        "# 3. DYNAMIC STUDENT CLUSTERING\n",
        "# =============================\n",
        "\n",
        "class StudentClusterer:\n",
        "    \"\"\"Base clusterer with BIC optimization and visualization\"\"\"\n",
        "\n",
        "    def __init__(self, max_clusters=10):\n",
        "        self.max_clusters = max_clusters\n",
        "        self.optimal_k = None\n",
        "        self.gmm = None\n",
        "\n",
        "    def validate_features(self, data):\n",
        "        \"\"\"Ensure data quality for clustering\"\"\"\n",
        "        return data.dropna()\n",
        "\n",
        "    def optimize_cluster_count(self, data):\n",
        "        \"\"\"Use BIC to choose optimal cluster count\"\"\"\n",
        "        data = self.validate_features(data)\n",
        "        bic_scores = []\n",
        "        k_range = range(1, self.max_clusters + 1)\n",
        "\n",
        "        for k in tqdm(k_range, desc=\"Computing BIC\"):\n",
        "            gmm = GaussianMixture(n_components=k, random_state=42)\n",
        "            gmm.fit(data)\n",
        "            bic_scores.append(gmm.bic(data))\n",
        "\n",
        "        # Find optimal k (min BIC)\n",
        "        self.optimal_k = np.argmin(bic_scores) + 1  # +1 because k starts at 1\n",
        "        return self.optimal_k, bic_scores\n",
        "\n",
        "    def fit_gmm(self, data):\n",
        "        \"\"\"Fit GMM with optimal k and return labels\"\"\"\n",
        "        if self.optimal_k is None:\n",
        "            self.optimize_cluster_count(data)\n",
        "\n",
        "        self.gmm = GaussianMixture(n_components=self.optimal_k, random_state=42)\n",
        "        self.gmm.fit(data)\n",
        "        return self.gmm.predict(data)\n",
        "\n",
        "    def plot_bic_curve(self, bic_scores, filename='bic_optimization.png'):\n",
        "        \"\"\"Plot BIC curve for model selection with optimal value marked\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        k_range = range(1, len(bic_scores) + 1)\n",
        "        plt.plot(k_range, bic_scores, 'bo-', label='BIC')\n",
        "\n",
        "        # Mark optimal value\n",
        "        optimal_k = np.argmin(bic_scores) + 1\n",
        "        min_bic = min(bic_scores)\n",
        "        plt.plot(optimal_k, min_bic, 'ro', markersize=8,\n",
        "                 label=f'Optimal k={optimal_k}')\n",
        "\n",
        "        plt.xlabel('Number of Clusters')\n",
        "        plt.ylabel('BIC Score')\n",
        "        plt.title('BIC for Gaussian Mixture Model')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(filename, dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "class EnhancedStudentClusterer(StudentClusterer):\n",
        "    \"\"\"Improved clustering with silhouette optimization and profile interpretation\"\"\"\n",
        "    \"\"\"Improved clustering with EM convergence monitoring\"\"\"\n",
        "\n",
        "    def __init__(self, max_clusters=10):\n",
        "        super().__init__(max_clusters)\n",
        "        self.cluster_metrics = {}\n",
        "        self.log_likelihoods = []\n",
        "\n",
        "    def validate_clusters(self, data, labels):\n",
        "        \"\"\"Compute multiple validation metrics for cluster quality\"\"\"\n",
        "        return {\n",
        "            \"silhouette\": silhouette_score(data, labels),\n",
        "            \"calinski_harabasz\": calinski_harabasz_score(data, labels),\n",
        "            \"davies_bouldin\": davies_bouldin_score(data, labels)\n",
        "        }\n",
        "\n",
        "    def optimize_cluster_count(self, data):\n",
        "        \"\"\"Use silhouette score instead of BIC for better profile separation\"\"\"\n",
        "        \"\"\"Use silhouette score with EM convergence monitoring\"\"\"\n",
        "        data = super().validate_features(data)\n",
        "\n",
        "        best_score = -1\n",
        "        best_k = 3\n",
        "        silhouette_scores = []\n",
        "        cluster_metrics = []\n",
        "        self.log_likelihoods = []  # Reset log-likelihoods\n",
        "\n",
        "        for k in range(2, self.max_clusters + 1):\n",
        "            # Configure GMM with convergence parameters\n",
        "            gmm = GaussianMixture(\n",
        "                n_components=k,\n",
        "                random_state=42,\n",
        "                max_iter=100,\n",
        "                tol=1e-4,\n",
        "                n_init=3\n",
        "            )\n",
        "\n",
        "            # Fit model and track convergence\n",
        "            gmm.fit(data)\n",
        "            labels = gmm.predict(data)\n",
        "\n",
        "            # Store EM convergence metrics\n",
        "            self.log_likelihoods.append(gmm.lower_bound_)\n",
        "\n",
        "            score = silhouette_score(data, labels)\n",
        "            silhouette_scores.append(score)\n",
        "\n",
        "            metrics = self.validate_clusters(data, labels)\n",
        "            cluster_metrics.append(metrics)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_k = k\n",
        "                best_metrics = metrics\n",
        "\n",
        "        self.optimal_k = best_k\n",
        "        self.cluster_metrics = cluster_metrics\n",
        "        return self.optimal_k, silhouette_scores\n",
        "\n",
        "\n",
        "    def interpret_clusters(self, score_matrix):\n",
        "        \"\"\"Analyze cluster characteristics to identify performance profiles\"\"\"\n",
        "        \"\"\"Improved cluster profiling with adjusted thresholds\"\"\"\n",
        "        cluster_profiles = []\n",
        "        global_variance = score_matrix['variance'].mean()\n",
        "        global_gap = score_matrix['max_min_gap'].mean()\n",
        "\n",
        "        for cluster_id in sorted(score_matrix['cluster'].unique()):\n",
        "            cluster_data = score_matrix[score_matrix['cluster'] == cluster_id]\n",
        "\n",
        "            profile = {\n",
        "                'cluster': cluster_id,\n",
        "                'size': len(cluster_data),\n",
        "                'overall_avg': cluster_data['overall_performance'].mean(),\n",
        "                'theory_avg': cluster_data['theory_avg'].mean(),\n",
        "                'practical_avg': cluster_data['practical_avg'].mean(),\n",
        "                'variance_avg': cluster_data['variance'].mean(),\n",
        "                'max_min_gap': cluster_data['max_min_gap'].mean(),\n",
        "                'weak_subject_count': cluster_data['weak_subject_count'].mean(),\n",
        "                'profile_type': \"\"\n",
        "            }\n",
        "\n",
        "            # Calculate metrics with new thresholds\n",
        "            gap = abs(profile['theory_avg'] - profile['practical_avg'])\n",
        "            variance_ratio = profile['variance_avg'] / global_variance\n",
        "            gap_ratio = profile['max_min_gap'] / global_gap\n",
        "\n",
        "            # Adjusted thresholds for better profiling\n",
        "            if profile['overall_avg'] > 75:\n",
        "                profile['profile_type'] = \"High Performers\"\n",
        "            elif profile['overall_avg'] < 55:  # Lowered threshold from 50\n",
        "                profile['profile_type'] = \"Low Performers\"\n",
        "            elif gap > 15 or (gap_ratio > 1.5 and gap > 10):  # Stricter thresholds\n",
        "                if profile['theory_avg'] > profile['practical_avg']:\n",
        "                    profile['profile_type'] = \"Theory-Focused\"\n",
        "                else:\n",
        "                    profile['profile_type'] = \"Practice-Focused\"\n",
        "            elif variance_ratio > 1.5 or profile['variance_avg'] > 80:  # reduced threshold\n",
        "                profile['profile_type'] = \"Inconsistent Learners\"\n",
        "            else:\n",
        "                profile['profile_type'] = \"Balanced Learners\"\n",
        "\n",
        "            cluster_profiles.append(profile)\n",
        "\n",
        "        return pd.DataFrame(cluster_profiles)\n",
        "\n",
        "    def plot_cluster_profiles(self, cluster_profile_df):\n",
        "        \"\"\"Visualize performance profiles\"\"\"\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Plot theory vs practical skills\n",
        "        for _, row in cluster_profile_df.iterrows():\n",
        "            plt.scatter(\n",
        "                row['theory_avg'],\n",
        "                row['practical_avg'],\n",
        "                s=row['size'] * 10,\n",
        "                label=f\"{row['profile_type']} (n={row['size']})\"\n",
        "            )\n",
        "\n",
        "        # Add reference lines\n",
        "        max_val = max(cluster_profile_df[['theory_avg', 'practical_avg']].max().max(), 100)\n",
        "        plt.plot([0, max_val], [0, max_val], 'k--', alpha=0.3)\n",
        "        plt.plot([50, max_val], [50, 50], 'r:', alpha=0.3)  # Passing threshold\n",
        "        plt.plot([50, 50], [50, max_val], 'r:', alpha=0.3)\n",
        "\n",
        "        plt.xlabel('Theory Skills (Avg Score)')\n",
        "        plt.ylabel('Practical Skills (Avg Score)')\n",
        "        plt.title('Student Performance Profiles')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig('performance_profiles.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    def plot_em_convergence(self, filename='em_convergence.png'):\n",
        "        \"\"\"Visualize EM algorithm convergence\"\"\"\n",
        "        if not self.log_likelihoods:\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        k_values = range(2, len(self.log_likelihoods) + 2)\n",
        "        plt.plot(k_values, self.log_likelihoods, 'go-')\n",
        "\n",
        "        # Mark optimal cluster count\n",
        "        optimal_idx = self.optimal_k - 2\n",
        "        plt.plot(self.optimal_k, self.log_likelihoods[optimal_idx], 'ro',\n",
        "                 markersize=8, label=f'Optimal k={self.optimal_k}')\n",
        "\n",
        "        plt.xlabel('Number of Clusters')\n",
        "        plt.ylabel('Log-Likelihood (ELBO)')\n",
        "        plt.title('EM Algorithm Convergence')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(filename, dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 4. PATHWAY OPTIMIZATION\n",
        "# =========================\n",
        "\n",
        "class PathwayGenerator:\n",
        "    \"\"\"\n",
        "    Creates personalized learning pathways based on:\n",
        "    - Performance clusters\n",
        "    - Vygotsky's Zone of Proximal Development (ZPD)\n",
        "    - Time constraints (T_max = 12 hrs/week)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, threshold=60, max_hours=12):  # Lowered threshold\n",
        "        self.threshold = threshold  # Performance threshold\n",
        "        self.max_hours = max_hours  # Weekly time constraint\n",
        "\n",
        "    def identify_weak_areas(self, scores):\n",
        "        \"\"\"Find courses where score < threshold\"\"\"\n",
        "        return [i for i, score in enumerate(scores) if score < self.threshold]\n",
        "\n",
        "    def calculate_zpd_level(self, current_score, cluster_mean):\n",
        "        \"\"\"\n",
        "        Compute resource difficulty level using Vygotsky's ZPD:\n",
        "        L_resource = S_current + 0.4 * (μ_cluster - S_current)\n",
        "        \"\"\"\n",
        "        # Handle cases where cluster mean isn't higher\n",
        "        if cluster_mean <= current_score:\n",
        "            # Provide minimum 5-point challenge\n",
        "            return min(100, current_score + 5)\n",
        "        else:\n",
        "            zpd = current_score + 0.4 * (cluster_mean - current_score)\n",
        "            # Ensure at least 5-point challenge\n",
        "            return max(current_score + 5, min(100, zpd))\n",
        "\n",
        "    def optimize_pathway(self, weak_areas, course_scores, cluster_means):\n",
        "        \"\"\"Optimized pathway using dynamic programming knapsack solution\"\"\"\n",
        "        if not weak_areas:\n",
        "            return []\n",
        "\n",
        "        # Calculate utility (performance gap) and weights (time)\n",
        "        #utility = [100 - course_scores[i] for i in weak_areas]\n",
        "        # Calculate utility as normalized gap\n",
        "        max_score = 100\n",
        "        utility = [(max_score - course_scores[i]) / max_score for i in weak_areas]\n",
        "        weights = [2] * len(weak_areas)  # 2 hours per resource\n",
        "        capacity = self.max_hours\n",
        "\n",
        "        # Initialize DP table\n",
        "        n = len(utility)\n",
        "        dp = [[0] * (capacity + 1) for _ in range(n + 1)]\n",
        "\n",
        "        # Build DP table\n",
        "        for i in range(1, n + 1):\n",
        "            for w in range(1, capacity + 1):\n",
        "                if weights[i - 1] <= w:\n",
        "                    dp[i][w] = max(dp[i - 1][w],\n",
        "                                   dp[i - 1][w - weights[i - 1]] + utility[i - 1])\n",
        "                else:\n",
        "                    dp[i][w] = dp[i - 1][w]\n",
        "\n",
        "        # Backtrack to find selected courses\n",
        "        selected = []\n",
        "        w = capacity\n",
        "        for i in range(n, 0, -1):\n",
        "            if dp[i][w] != dp[i - 1][w]:\n",
        "                selected.append(weak_areas[i - 1])\n",
        "                w -= weights[i - 1]\n",
        "\n",
        "        # Generate pathway with ZPD-level resources\n",
        "        pathway = []\n",
        "        for area in selected:\n",
        "            zpd_level = self.calculate_zpd_level(\n",
        "                course_scores[area],\n",
        "                cluster_means[area]\n",
        "            )\n",
        "            pathway.append({\n",
        "                'course_index': area,\n",
        "                'zpd_level': round(zpd_level, 1),\n",
        "                'study_hours': 2,\n",
        "                'resources': self.select_resources(zpd_level)\n",
        "            })\n",
        "\n",
        "        return pathway\n",
        "\n",
        "    def select_resources(self, zpd_level):\n",
        "        \"\"\"Match resources to difficulty level (simulated)\"\"\"\n",
        "        # In production: Query resource database with difficulty filter\n",
        "        difficulty_bracket = int(zpd_level // 10) * 10  # Group by 10-point brackets\n",
        "\n",
        "        return [\n",
        "            f\"Video Lecture (Level: {difficulty_bracket}-{difficulty_bracket + 9})\",\n",
        "            f\"Practice Problems (Level: {difficulty_bracket}-{difficulty_bracket + 9})\",\n",
        "            f\"Interactive Simulation (Level: {difficulty_bracket}-{difficulty_bracket + 9})\"\n",
        "        ]\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 5. BLOCKCHAIN INTEGRATION\n",
        "# =======================\n",
        "\n",
        "class BlockchainSimulator:\n",
        "    \"\"\"\n",
        "    Simulates Hyperledger Fabric functionality for:\n",
        "    - IPFS content addressing\n",
        "    - On-chain hash storage\n",
        "    - Academic record verification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.chain = []\n",
        "        self.records = {}\n",
        "\n",
        "    def store_pathway(self, student_id, pathway_data):\n",
        "        \"\"\"Store pathway hash on blockchain with timestamp\"\"\"\n",
        "        # Simulate IPFS storage\n",
        "        cid = self._ipfs_store(pathway_data)\n",
        "\n",
        "        # Create blockchain record\n",
        "        timestamp = datetime.now().isoformat()\n",
        "        record = {\n",
        "            'student_id': student_id,\n",
        "            'ipfs_cid': cid,\n",
        "            'timestamp': timestamp,\n",
        "            'tx_hash': hashlib.sha256(f\"{student_id}{timestamp}\".encode()).hexdigest()\n",
        "        }\n",
        "\n",
        "        # Add to chain\n",
        "        self.chain.append(record)\n",
        "        self.records[student_id] = record\n",
        "        return record\n",
        "\n",
        "    def _ipfs_store(self, data):\n",
        "        \"\"\"Simulate IPFS storage (returns content identifier)\"\"\"\n",
        "        json_data = json.dumps(data).encode()\n",
        "        return f\"Qm{hashlib.sha256(json_data).hexdigest()[:46]}\"\n",
        "\n",
        "    def verify_record(self, student_id):\n",
        "        \"\"\"Verify pathway integrity using blockchain records\"\"\"\n",
        "        return self.records.get(student_id)\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 6. VISUALIZATION TOOLS\n",
        "# ======================\n",
        "\n",
        "class ResultVisualizer:\n",
        "    \"\"\"Generates publication-quality visualizations of results\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_score_comparison(pre_scores, post_scores):\n",
        "        \"\"\"Visualize pre/post intervention score distribution\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Kernel Density Estimation plots with bandwidth adjustment\n",
        "        sns.kdeplot(pre_scores, fill=True, label='Pre-Intervention',\n",
        "                    alpha=0.5, bw_adjust=0.5)  # Added bw_adjust for smoothing\n",
        "        sns.kdeplot(post_scores, fill=True, label='Post-Intervention',\n",
        "                    alpha=0.5, bw_adjust=0.5)  # Added bw_adjust for smoothing\n",
        "\n",
        "        # Set y-axis limits\n",
        "        plt.ylim(0, 0.035)  # Increased y-axis range\n",
        "\n",
        "        plt.title('Score Distribution Improvement', fontsize=16)\n",
        "        plt.xlabel('Scores', fontsize=14)\n",
        "        plt.ylabel('Density', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.savefig('score_distribution_comparison.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_cluster_performance(cluster_data):\n",
        "        \"\"\"Visualize cluster-specific improvements\"\"\"\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        clusters = sorted(cluster_data['cluster'].unique())\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(clusters)))\n",
        "\n",
        "        for i, cluster in enumerate(clusters):\n",
        "            cluster_df = cluster_data[cluster_data['cluster'] == cluster]\n",
        "            plt.scatter(\n",
        "                cluster_df['pre_score'],\n",
        "                cluster_df['post_score'],\n",
        "                color=colors[i],\n",
        "                label=f'Cluster {cluster}: {cluster_df[\"profile_type\"].iloc[0]}',\n",
        "                alpha=0.7\n",
        "            )\n",
        "\n",
        "        # Add identity line\n",
        "        max_score = max(cluster_data[['pre_score', 'post_score']].max().max(), 100)\n",
        "        plt.plot([0, max_score], [0, max_score], 'k--', alpha=0.5)\n",
        "        plt.plot([50, max_score], [50, 50], 'r:', alpha=0.3)  # Passing threshold\n",
        "        plt.plot([50, 50], [50, max_score], 'r:', alpha=0.3)\n",
        "\n",
        "        plt.title('Pre-vs-Post Scores by Cluster', fontsize=16)\n",
        "        plt.xlabel('Pre-Intervention Scores', fontsize=14)\n",
        "        plt.ylabel('Post-Intervention Scores', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.5)\n",
        "        plt.savefig('cluster_performance.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_cluster_validation(metrics):\n",
        "        \"\"\"Visualize cluster validation metrics\"\"\"\n",
        "        fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "        # Silhouette and Calinski-Harabasz\n",
        "        k_values = range(2, len(metrics) + 2)\n",
        "        sil_scores = [m['silhouette'] for m in metrics]\n",
        "        cal_scores = [m['calinski_harabasz'] for m in metrics]\n",
        "\n",
        "        ax1.plot(k_values, sil_scores, 'b-o', label='Silhouette Score')\n",
        "        ax1.set_xlabel('Number of Clusters')\n",
        "        ax1.set_ylabel('Silhouette Score', color='b')\n",
        "        ax1.tick_params('y', colors='b')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.plot(k_values, cal_scores, 'r--o', label='Calinski-Harabasz Index')\n",
        "        ax2.set_ylabel('Calinski-Harabasz Index', color='r')\n",
        "        ax2.tick_params('y', colors='r')\n",
        "        fig.tight_layout()\n",
        "        plt.savefig('cluster_validation.png', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_performance_metrics(score_matrix, post_scores, pathways, courses, cluster_profiles):\n",
        "        \"\"\"\n",
        "        Compute comprehensive performance metrics:\n",
        "        1. Learning gain by cluster\n",
        "        2. Weak area remediation rate\n",
        "        3. Pathway efficiency\n",
        "        4. Resource utilization\n",
        "        5. Equity impact\n",
        "        6. Improvement list\n",
        "        \"\"\"\n",
        "        metrics = {}\n",
        "        improvements = []  # NEW: Store individual improvements\n",
        "\n",
        "        # 1. Overall learning gain\n",
        "        all_pre = score_matrix[courses].values.flatten()\n",
        "        all_post = post_scores[courses].values.flatten()\n",
        "        metrics['overall_improvement'] = np.mean(all_post - all_pre)\n",
        "\n",
        "        # 2. Cluster-specific gains\n",
        "        cluster_improvements = {}\n",
        "        for cluster_id in cluster_profiles['cluster']:\n",
        "            cluster_students = score_matrix[score_matrix['cluster'] == cluster_id].index\n",
        "            pre_avg = score_matrix.loc[cluster_students, courses].mean().mean()\n",
        "            post_avg = post_scores.loc[cluster_students, courses].mean().mean()\n",
        "            cluster_improvements[cluster_id] = {\n",
        "                'improvement': post_avg - pre_avg,\n",
        "                'size': len(cluster_students)\n",
        "            }\n",
        "        metrics['cluster_improvements'] = cluster_improvements\n",
        "\n",
        "        # 3. Weak area remediation\n",
        "        resolved_weak_areas = 0\n",
        "        total_weak_areas = 0\n",
        "\n",
        "        # NEW: Calculate individual student improvements\n",
        "        for student in score_matrix.index:\n",
        "            pre_avg = score_matrix.loc[student, courses].mean()\n",
        "            post_avg = post_scores.loc[student, courses].mean()\n",
        "            student_improvement = post_avg - pre_avg\n",
        "            improvements.append(student_improvement)\n",
        "\n",
        "            # Weak area analysis\n",
        "            weak_areas = [i for i, score in enumerate(score_matrix.loc[student, courses]) if score < 60]\n",
        "            total_weak_areas += len(weak_areas)\n",
        "\n",
        "            if student in pathways and pathways[student]:\n",
        "                for item in pathways[student]:\n",
        "                    course_idx = item['course_index']\n",
        "                    if post_scores.loc[student, courses[course_idx]] >= 60:\n",
        "                        resolved_weak_areas += 1\n",
        "\n",
        "        metrics['improvements'] = improvements  # NEW: Store for equity plot\n",
        "        metrics['weak_area_resolution'] = resolved_weak_areas / total_weak_areas if total_weak_areas > 0 else 0\n",
        "\n",
        "        # 4. Pathway efficiency\n",
        "        study_hours = []\n",
        "        for pathway in pathways.values():\n",
        "            if pathway:\n",
        "                study_hours.append(sum(item['study_hours'] for item in pathway))\n",
        "        metrics['avg_study_hours'] = np.mean(study_hours) if study_hours else 0\n",
        "\n",
        "        # 5. Equity impact (Gini coefficient of improvement)\n",
        "        sorted_improvements = np.sort(improvements)\n",
        "        n = len(sorted_improvements)\n",
        "        index = np.arange(1, n + 1)\n",
        "        gini = (np.sum((2 * index - n - 1) * sorted_improvements)) / (n * np.sum(sorted_improvements))\n",
        "        metrics['gini_improvement'] = gini\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_improvement_by_cluster(metrics, filename='cluster_improvements.png'):\n",
        "        \"\"\"Visualize improvement by cluster profile\"\"\"\n",
        "        cluster_data = []\n",
        "        for cluster_id, data in metrics['cluster_improvements'].items():\n",
        "            cluster_data.append({\n",
        "                'cluster': cluster_id,\n",
        "                'improvement': data['improvement'],\n",
        "                'size': data['size']\n",
        "            })\n",
        "        cluster_df = pd.DataFrame(cluster_data)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        ax = sns.barplot(x='cluster', y='improvement', data=cluster_df,\n",
        "                         palette='viridis', hue='size', dodge=False)\n",
        "\n",
        "        # Add size annotations\n",
        "        for i, row in enumerate(cluster_df.itertuples()):\n",
        "            ax.text(i, row.improvement + 0.2, f\"n={row.size}\",\n",
        "                    ha='center', fontsize=10)\n",
        "\n",
        "        plt.title('Average Score Improvement by Cluster', fontsize=16)\n",
        "        plt.xlabel('Cluster', fontsize=14)\n",
        "        plt.ylabel('Score Improvement', fontsize=14)\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_equity_impact(improvements, filename='equity_impact.png'):\n",
        "        \"\"\"Visualize improvement distribution using Lorenz curve\"\"\"\n",
        "        sorted_improvements = np.sort(improvements)\n",
        "        cumulative = np.cumsum(sorted_improvements)\n",
        "        cumulative = cumulative / cumulative[-1] if cumulative[-1] != 0 else cumulative\n",
        "\n",
        "        perfect = np.linspace(0, 1, len(improvements))\n",
        "\n",
        "        # Calculate Gini coefficient\n",
        "        n = len(sorted_improvements)\n",
        "        index = np.arange(1, n + 1)\n",
        "        gini = (np.sum((2 * index - n - 1) * sorted_improvements)) / (n * np.sum(sorted_improvements))\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(perfect, cumulative, label='Actual Improvement')\n",
        "        plt.plot(perfect, perfect, 'k--', label='Perfect Equality')\n",
        "\n",
        "        # Fill area between curves\n",
        "        plt.fill_between(perfect, perfect, cumulative, alpha=0.1)\n",
        "\n",
        "        # Add Gini annotation\n",
        "        plt.annotate(f'Gini: {gini:.3f}', xy=(0.6, 0.3), fontsize=12,\n",
        "                     bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.8))\n",
        "\n",
        "        plt.title('Equity of Learning Improvements', fontsize=16)\n",
        "        plt.xlabel('Percentage of Students', fontsize=14)\n",
        "        plt.ylabel('Cumulative Improvement Share', fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.savefig(filename, dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_radar_chart(comparison_df, filename=\"radar_chart.png\"):\n",
        "        \"\"\"Create radar chart visualization of model metrics\"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        from math import pi\n",
        "\n",
        "        # Prepare data\n",
        "        models = comparison_df[\"Model\"].values\n",
        "        metrics = [\"Coherence\", \"Distinctiveness\", \"Relevance\"]\n",
        "        values = comparison_df[metrics].values\n",
        "\n",
        "        # Normalize values to 0-1 scale\n",
        "        normalized = (values - values.min(axis=0)) / (values.max(axis=0) - values.min(axis=0) + 1e-8)\n",
        "\n",
        "        # Compute angles\n",
        "        N = len(metrics)\n",
        "        angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "        angles += angles[:1]\n",
        "\n",
        "        # Create plot\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        ax = fig.add_subplot(111, polar=True)\n",
        "        ax.set_theta_offset(pi / 2)\n",
        "        ax.set_theta_direction(-1)\n",
        "        plt.xticks(angles[:-1], metrics)\n",
        "\n",
        "        # Draw ylabels\n",
        "        ax.set_rlabel_position(0)\n",
        "        plt.yticks([0.25, 0.5, 0.75], [\"0.25\", \"0.5\", \"0.75\"], color=\"grey\", size=10)\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        # Plot each model\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(models)))\n",
        "        for i, model in enumerate(models):\n",
        "            stats = normalized[i].tolist()\n",
        "            stats += stats[:1]  # Close the polygon\n",
        "            ax.plot(angles, stats, linewidth=2, linestyle='solid', label=model, color=colors[i])\n",
        "            ax.fill(angles, stats, alpha=0.1, color=colors[i])\n",
        "\n",
        "        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "        plt.title(\"Topic Model Comparison\", size=16, y=1.1)\n",
        "        plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# ========================\n",
        "# TOPIC MODELING CLASSES\n",
        "# ========================\n",
        "\n",
        "class LDAOnlyModel:\n",
        "    \"\"\"Wrapper for LDA-only topic modeling\"\"\"\n",
        "\n",
        "    def __init__(self, n_topics=5):\n",
        "        self.n_topics = n_topics\n",
        "        self.vectorizer = None\n",
        "        self.lda = None\n",
        "\n",
        "    def train(self, documents):\n",
        "        \"\"\"Train LDA model\"\"\"\n",
        "        academic_stop_words = ['student', 'professor', 'university', 'chapter', 'section',\n",
        "                               'example', 'problem', 'solution', 'study', 'learn']\n",
        "        self.vectorizer = CountVectorizer(max_df=0.85, min_df=3, stop_words='english',\n",
        "                                          ngram_range=(1, 2), max_features=1000)\n",
        "        self.vectorizer.stop_words_ = set(list(self.vectorizer.get_stop_words()) + academic_stop_words)\n",
        "        dtm = self.vectorizer.fit_transform(documents)\n",
        "        self.lda = LatentDirichletAllocation(n_components=self.n_topics, random_state=42)\n",
        "        self.lda.fit(dtm)\n",
        "\n",
        "    def get_dominant_topic(self, documents):\n",
        "        \"\"\"Get dominant topic for documents\"\"\"\n",
        "        if not self.lda:\n",
        "            self.train(documents)\n",
        "        dtm = self.vectorizer.transform(documents)\n",
        "        return np.argmax(self.lda.transform(dtm), axis=1)\n",
        "\n",
        "\n",
        "class BERTOnlyModel:\n",
        "    \"\"\"Wrapper for BERT-only topic modeling\"\"\"\n",
        "\n",
        "    def __init__(self, n_topics=5):\n",
        "        self.n_topics = n_topics\n",
        "        self.bert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        self.kmeans = KMeans(n_clusters=n_topics, random_state=42)\n",
        "\n",
        "    def get_dominant_topic(self, documents):\n",
        "        \"\"\"Get dominant topic for documents\"\"\"\n",
        "        embeddings = self.bert_model.encode(documents)\n",
        "        return self.kmeans.fit_predict(embeddings)\n",
        "\n",
        "# =========================\n",
        "# 7. MAIN EXECUTION PIPELINE\n",
        "# =========================\n",
        "def generate_template_file():\n",
        "    \"\"\"Create assessment template CSV if it doesn't exist\"\"\"\n",
        "    if os.path.exists(TEMPLATES_FILENAME):\n",
        "        return\n",
        "\n",
        "    templates = {\n",
        "        \"course\": [\n",
        "            \"Calculus I\", \"Calculus I\", \"Calculus I\", \"Calculus I\",\n",
        "            \"Physics I\", \"Physics I\", \"Physics I\", \"Physics I\",\n",
        "            \"Programming Fundamentals\", \"Programming Fundamentals\", \"Programming Fundamentals\",\n",
        "            \"Programming Fundamentals\",\n",
        "            \"Engineering Drawing\", \"Engineering Drawing\", \"Engineering Drawing\", \"Engineering Drawing\",\n",
        "            \"Electrical Circuits\", \"Electrical Circuits\", \"Electrical Circuits\", \"Electrical Circuits\"\n",
        "        ],\n",
        "        \"template\": [\n",
        "            \"Differential calculus problems involving {}\",\n",
        "            \"Integral calculus applications in {}\",\n",
        "            \"Limits and continuity exercises on {}\",\n",
        "            \"Derivative applications for {} problems\",\n",
        "            \"Kinematics problems in {} dimensions\",\n",
        "            \"Dynamics of systems with {} interactions\",\n",
        "            \"Thermodynamics applications for {} systems\",\n",
        "            \"Electromagnetism principles in {} contexts\",\n",
        "            \"Algorithms implementation using {} approach\",\n",
        "            \"Data structures exercises with {} applications\",\n",
        "            \"Object-oriented programming concepts for {}\",\n",
        "            \"Problem-solving techniques with {} paradigm\",\n",
        "            \"Orthographic projection of {} objects\",\n",
        "            \"Isometric drawing techniques for {} structures\",\n",
        "            \"CAD modeling exercises for {} components\",\n",
        "            \"Dimensioning standards applied to {} designs\",\n",
        "            \"Analysis of {} circuits using Kirchhoff's laws\",\n",
        "            \"AC circuit behavior with {} components\",\n",
        "            \"Transient response in {} networks\",\n",
        "            \"Power distribution systems for {} applications\"\n",
        "        ],\n",
        "        \"topic\": [\n",
        "            \"polynomial functions\", \"trigonometric functions\", \"exponential growth\", \"optimization\",\n",
        "            \"mechanical systems\", \"fluid dynamics\", \"electromagnetic fields\", \"thermal systems\",\n",
        "            \"sorting algorithms\", \"tree structures\", \"inheritance patterns\", \"recursive solutions\",\n",
        "            \"mechanical parts\", \"architectural elements\", \"piping systems\", \"electrical components\",\n",
        "            \"resistive networks\", \"capacitive circuits\", \"inductive loads\", \"filter designs\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    pd.DataFrame(templates).to_csv(TEMPLATES_FILENAME, index=False)\n",
        "    print(f\"Created assessment template file: {TEMPLATES_FILENAME}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if IN_COLAB:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "        # Download NLTK punkt_tab resource\n",
        "        nltk.download('punkt_tab')\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"SANKOFA PATHWAYS: Personalized Learning System\")\n",
        "    print(\"Soroti University Implementation (Google Colab)\" if IN_COLAB else \"Local Execution\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Define courses\n",
        "    courses = [\n",
        "        \"Calculus I\", \"Physics I\", \"Programming Fundamentals\",\n",
        "        \"Engineering Drawing\", \"Electrical Circuits\"\n",
        "    ]\n",
        "\n",
        "    # Generate template file if needed\n",
        "    generate_template_file()\n",
        "\n",
        "    # --------------------\n",
        "    # 1. Generate or load mock data\n",
        "    # --------------------\n",
        "    if os.path.exists(DATASET_FILENAME):\n",
        "        print(f\"\\n[1/6] Loading dataset from {DATASET_FILENAME}...\")\n",
        "        raw_df = pd.read_csv(DATASET_FILENAME)\n",
        "    else:\n",
        "        print(\"\\n[1/6] Generating synthetic dataset...\")\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Load assessment templates\n",
        "        templates_df = pd.read_csv(TEMPLATES_FILENAME)\n",
        "        print(f\"Loaded assessment templates from {TEMPLATES_FILENAME}\")\n",
        "\n",
        "        # Create 100 student records with multiple assessments\n",
        "        student_ids = [f\"STU{1000 + i}\" for i in range(100)]\n",
        "        data = []\n",
        "        assessment_types = ['Test 1', 'Test 2', 'Coursework 1', 'Coursework 2', 'Final Exam']\n",
        "\n",
        "        # Create distinct student groups\n",
        "        for i, student in enumerate(student_ids):\n",
        "            # Create 3 distinct performance groups\n",
        "            if i < 30:  # Low performers\n",
        "                base_score = np.random.normal(45, 8)\n",
        "            elif i < 70:  # Medium performers\n",
        "                base_score = np.random.normal(65, 10)\n",
        "            else:  # High performers\n",
        "                base_score = np.random.normal(80, 6)\n",
        "\n",
        "            for course in courses:\n",
        "                # Get templates for this course\n",
        "                course_templates = templates_df[templates_df['course'] == course]\n",
        "\n",
        "                # Generate 5 assessments per course\n",
        "                for assessment_idx, assessment_name in enumerate(assessment_types):\n",
        "                    # Add course-specific variations\n",
        "                    course_adjustment = np.random.uniform(-5, 5)\n",
        "\n",
        "                    # Assessment-specific variation\n",
        "                    if assessment_name == 'Final Exam':\n",
        "                        assessment_adjust = np.random.uniform(-3, 3)\n",
        "                    else:\n",
        "                        assessment_adjust = np.random.uniform(-8, 8)\n",
        "\n",
        "                    score = base_score + course_adjustment + assessment_adjust\n",
        "                    score = max(0, min(100, score))\n",
        "\n",
        "                    # Select random template and topic\n",
        "                    template_row = course_templates.sample(1).iloc[0]\n",
        "                    template = template_row['template']\n",
        "                    topic = template_row['topic']\n",
        "                    assessment_text = f\"{assessment_name}: \" + template.format(topic)\n",
        "\n",
        "                    data.append({\n",
        "                        'student_id': student,\n",
        "                        'course': course,\n",
        "                        'score': score,\n",
        "                        'assessment_text': assessment_text,\n",
        "                        'assessment_type': assessment_name,\n",
        "                        'assessment_idx': assessment_idx\n",
        "                    })\n",
        "\n",
        "        raw_df = pd.DataFrame(data)\n",
        "        raw_df.to_csv(DATASET_FILENAME, index=False)\n",
        "        print(f\"Saved dataset to {DATASET_FILENAME}\")\n",
        "\n",
        "    # -------------------\n",
        "    # 2. Preprocess data\n",
        "    # -------------------\n",
        "    print(\"[2/6] Preprocessing data with differential privacy...\")\n",
        "    preprocessor = DataPreprocessor(epsilon=0.85)\n",
        "    processed_df = preprocessor.preprocess(raw_df)\n",
        "\n",
        "    # Pivot to student-course matrix\n",
        "    score_matrix = processed_df.pivot_table(\n",
        "        index='hashed_id',\n",
        "        columns='course',\n",
        "        values='score',\n",
        "        aggfunc='mean'\n",
        "    ).fillna(65)  # Fill missing with mean\n",
        "\n",
        "    # Ensure no missing values remain\n",
        "    score_matrix = score_matrix.fillna(score_matrix.median())\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3. Hybrid topic modeling\n",
        "    # ---------------------------\n",
        "    print(\"[3/6] Performing advanced hybrid topic modeling...\")\n",
        "    documents = processed_df['assessment_text'].unique()\n",
        "\n",
        "    # Create all models for comprehensive comparison\n",
        "    models_to_compare = {\n",
        "        \"LDA Only\": LDAOnlyModel(n_topics=5),\n",
        "        \"BERT Only\": BERTOnlyModel(n_topics=5),\n",
        "        \"Original Hybrid\": HybridTopicModel(lambda_weight=0.85, n_topics=5),\n",
        "        \"Enhanced Hybrid\": EnhancedHybridTopicModel(\n",
        "            lambda_weight=0.85,  # More weight to BERT semantics\n",
        "            n_topics=7,  # Slightly more topics\n",
        "            fine_tune_steps=200  # More fine-tuning\n",
        "        )\n",
        "    }\n",
        "\n",
        "    # Train models\n",
        "    print(\"Training models for comparison...\")\n",
        "    for name, model in models_to_compare.items():\n",
        "        if name == \"LDA Only\" or name == \"BERT Only\":\n",
        "            continue  # Will be handled in evaluation\n",
        "\n",
        "        print(f\"- Training {name}...\")\n",
        "        if FINE_TUNE_BERT and IN_COLAB:\n",
        "            model.fine_tune_bert(documents)\n",
        "\n",
        "        if name == \"Original Hybrid\":\n",
        "            model.train_lda(documents)\n",
        "            # Ensure topic embeddings are computed\n",
        "            if not hasattr(model, 'topic_embeddings') or model.topic_embeddings is None:\n",
        "                model.compute_topic_embeddings(documents)\n",
        "        elif name == \"Enhanced Hybrid\":\n",
        "            # This handles all training internally\n",
        "            model.compute_topic_embeddings(documents)\n",
        "\n",
        "    # Evaluate and compare all models\n",
        "    if not PRODUCTION_MODE:\n",
        "        print(\"\\n[3.5/6] Comprehensive model evaluation...\")\n",
        "        evaluator = TopicModelEvaluator(\n",
        "            documents=processed_df['assessment_text'].tolist(),\n",
        "            n_topics=5\n",
        "        )\n",
        "\n",
        "        # Perform comprehensive evaluation\n",
        "        comparison_df, report = evaluator.comprehensive_evaluation(models_to_compare)\n",
        "\n",
        "        # Print and save report\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"MODEL COMPARISON RESULTS:\")\n",
        "        print(\"=\" * 70)\n",
        "        print(report)\n",
        "\n",
        "        # Save detailed report\n",
        "        with open(\"model_comparison_report.txt\", \"w\") as f:\n",
        "            f.write(report)\n",
        "\n",
        "        print(\"\\nVisualizations saved:\")\n",
        "        print(\"- model_metrics_comparison.png\")\n",
        "        print(\"- radar_chart.png\")\n",
        "        print(\"- topic_quality_scatter.png\")\n",
        "        print(\"- model_comparison_report.txt\")\n",
        "\n",
        "        # Use the best model for the rest of the pipeline\n",
        "        best_model_name = comparison_df.iloc[0][\"Model\"]\n",
        "        print(f\"\\nSelected best model for the pipeline: {best_model_name}\")\n",
        "        topic_model = models_to_compare[best_model_name]\n",
        "    else:\n",
        "        # In production, default to enhanced hybrid\n",
        "        topic_model = models_to_compare[\"Enhanced Hybrid\"]\n",
        "        print(\"Using Enhanced Hybrid model in production mode\")\n",
        "\n",
        "    # Continue with the selected model\n",
        "    print(\"Computing document-topic distributions...\")\n",
        "    processed_df['dominant_topic'] = topic_model.get_dominant_topic(\n",
        "        processed_df['assessment_text'].tolist()\n",
        "    )\n",
        "\n",
        "    # Create topic distribution per student\n",
        "    topic_dist = pd.crosstab(\n",
        "        index=processed_df['hashed_id'],\n",
        "        columns=processed_df['dominant_topic'],\n",
        "        normalize='index'\n",
        "    ).add_prefix('topic_')\n",
        "\n",
        "    # -------------------------\n",
        "    # 4. Student clustering\n",
        "    # -------------------------\n",
        "    print(\"[4/6] Clustering students...\")\n",
        "\n",
        "    # Initialize visualizer\n",
        "    visualizer = ResultVisualizer()\n",
        "\n",
        "    # Prepare feature matrix: scores + topic distribution\n",
        "    feature_matrix = pd.concat([score_matrix, topic_dist], axis=1)\n",
        "\n",
        "    # Feature engineering - create all necessary columns\n",
        "    feature_matrix['theory_avg'] = feature_matrix[['Calculus I', 'Physics I']].mean(axis=1)\n",
        "    feature_matrix['practical_avg'] = feature_matrix[\n",
        "        ['Programming Fundamentals', 'Engineering Drawing', 'Electrical Circuits']].mean(axis=1)\n",
        "    feature_matrix['overall_performance'] = feature_matrix[courses].mean(axis=1)\n",
        "    feature_matrix['variance'] = feature_matrix[courses].var(axis=1)\n",
        "    feature_matrix['theory_practical_gap'] = abs(feature_matrix['theory_avg'] - feature_matrix['practical_avg'])\n",
        "    feature_matrix['max_score'] = feature_matrix[courses].max(axis=1)\n",
        "    feature_matrix['min_score'] = feature_matrix[courses].min(axis=1)\n",
        "    feature_matrix['max_min_gap'] = feature_matrix['max_score'] - feature_matrix['min_score']\n",
        "    feature_matrix['weak_subject_count'] = (feature_matrix[courses] < 60).sum(axis=1)\n",
        "    feature_matrix['strong_subject_count'] = (feature_matrix[courses] > 80).sum(axis=1)\n",
        "\n",
        "    # Additional features\n",
        "    feature_matrix['theory_ratio'] = feature_matrix['theory_avg'] / feature_matrix['overall_performance']\n",
        "    feature_matrix['practical_ratio'] = feature_matrix['practical_avg'] / feature_matrix['overall_performance']\n",
        "    feature_matrix['imbalance_score'] = abs(feature_matrix['theory_ratio'] - 0.5)\n",
        "    feature_matrix['weakness_factor'] = feature_matrix['weak_subject_count'] / len(courses)\n",
        "\n",
        "    # Remove non-numeric columns for clustering\n",
        "    clustering_features = feature_matrix.select_dtypes(include=[np.number])\n",
        "\n",
        "    # Ensure proper alignment and no missing values\n",
        "    clustering_features = clustering_features.dropna()\n",
        "\n",
        "    # Create enhanced clusterer\n",
        "    clusterer = EnhancedStudentClusterer(max_clusters=8)\n",
        "    optimal_k, silhouette_scores = clusterer.optimize_cluster_count(clustering_features)\n",
        "    print(f\"Optimal cluster count: {optimal_k} (Silhouette optimized)\")\n",
        "\n",
        "    # Fit GMM and assign clusters\n",
        "    cluster_labels = clusterer.fit_gmm(clustering_features)\n",
        "    score_matrix['cluster'] = cluster_labels\n",
        "    feature_matrix['cluster'] = cluster_labels\n",
        "\n",
        "    # Interpret clusters and add profiles\n",
        "    cluster_profiles = clusterer.interpret_clusters(feature_matrix)\n",
        "    profile_mapping = cluster_profiles.set_index('cluster')['profile_type'].to_dict()\n",
        "    feature_matrix['profile_type'] = feature_matrix['cluster'].map(profile_mapping)\n",
        "    score_matrix['profile_type'] = feature_matrix['profile_type']\n",
        "\n",
        "    # Print cluster statistics\n",
        "    print(\"\\nCluster Statistics:\")\n",
        "    print(feature_matrix.groupby('cluster').agg({\n",
        "        'overall_performance': ['mean', 'std'],\n",
        "        'theory_avg': 'mean',\n",
        "        'practical_avg': 'mean',\n",
        "        'variance': 'mean',\n",
        "        'weak_subject_count': 'mean'\n",
        "    }))\n",
        "\n",
        "    # Print cluster validation metrics\n",
        "    print(\"\\nCluster Validation Metrics:\")\n",
        "    if optimal_k >= 2 and len(clusterer.cluster_metrics) >= optimal_k - 1:\n",
        "        metrics_index = optimal_k - 2\n",
        "        print(f\"Silhouette Score: {clusterer.cluster_metrics[metrics_index]['silhouette']:.3f}\")\n",
        "        print(f\"Calinski-Harabasz: {clusterer.cluster_metrics[metrics_index]['calinski_harabasz']:.1f}\")\n",
        "        print(f\"Davies-Bouldin: {clusterer.cluster_metrics[metrics_index]['davies_bouldin']:.3f}\")\n",
        "\n",
        "    # Visualize clusters\n",
        "    clusterer.plot_cluster_profiles(cluster_profiles)\n",
        "    if clusterer.cluster_metrics:\n",
        "        visualizer.plot_cluster_validation(clusterer.cluster_metrics)\n",
        "\n",
        "    # ------------------------\n",
        "    # 5. Pathway generation\n",
        "    # ------------------------\n",
        "    print(\"[5/6] Generating personalized pathways...\")\n",
        "    pathway_gen = PathwayGenerator(threshold=60, max_hours=12)\n",
        "    blockchain = BlockchainSimulator()\n",
        "\n",
        "    pathways = {}\n",
        "    students_with_pathways = 0\n",
        "\n",
        "    # Create reverse ID mapping\n",
        "    reverse_mapping = {v: k for k, v in preprocessor.id_mapping.items()}\n",
        "\n",
        "    for student in tqdm(score_matrix.index, desc=\"Generating pathways\"):\n",
        "        student_scores = score_matrix.loc[student, courses].values\n",
        "        cluster_id = score_matrix.loc[student, 'cluster']\n",
        "\n",
        "        # Use cluster mean from feature matrix\n",
        "        cluster_mean = feature_matrix[feature_matrix['cluster'] == cluster_id][courses].mean().values\n",
        "\n",
        "        weak_areas = pathway_gen.identify_weak_areas(student_scores)\n",
        "        pathway = pathway_gen.optimize_pathway(\n",
        "            weak_areas, student_scores, cluster_mean\n",
        "        )\n",
        "\n",
        "        if pathway:  # Only store if pathway is not empty\n",
        "            blockchain.store_pathway(student, pathway)\n",
        "            pathways[student] = pathway\n",
        "            students_with_pathways += 1\n",
        "\n",
        "    # Save all pathways to CSV\n",
        "    pathway_output = []\n",
        "    for hashed_id, pathway in pathways.items():\n",
        "        original_id = reverse_mapping.get(hashed_id, hashed_id)\n",
        "        for item in pathway:\n",
        "            course_name = courses[item['course_index']]\n",
        "            pathway_output.append({\n",
        "                'student_id': original_id,\n",
        "                'hashed_id': hashed_id,\n",
        "                'cluster': score_matrix.loc[hashed_id, 'cluster'],\n",
        "                'profile_type': score_matrix.loc[hashed_id, 'profile_type'],\n",
        "                'course': course_name,\n",
        "                'current_score': score_matrix.loc[hashed_id, course_name],\n",
        "                'zpd_level': item['zpd_level'],\n",
        "                'study_hours': item['study_hours'],\n",
        "                'resources': \", \".join(item['resources'])\n",
        "            })\n",
        "\n",
        "    pathway_df = pd.DataFrame(pathway_output)\n",
        "    pathway_df.to_csv(\"all_student_pathways.csv\", index=False)\n",
        "    print(f\"Saved all pathways to all_student_pathways.csv\")\n",
        "\n",
        "    # --------------------\n",
        "    # 6. Simulate results\n",
        "    # --------------------\n",
        "    print(\"[6/6] Simulating intervention and visualizing results...\")\n",
        "\n",
        "    # Simulate post-intervention scores with cluster-based improvements\n",
        "    post_scores = score_matrix.copy()\n",
        "    improvement_factors = {\n",
        "        \"Low Performers\": 0.40, #was 0.3, then o.35 now increased to 0.40\n",
        "        \"Inconsistent Learners\": 0.35, #was 0.25, then 0.30, now 0.35\n",
        "        \"Balanced Learners\": 0.22, #was 0.2\n",
        "        \"Theory-Focused\": 0.25, #was 0.22\n",
        "        \"Practice-Focused\": 0.28, #was 0.22\n",
        "        \"High Performers\": 0.12 #was 0.15\n",
        "    }\n",
        "\n",
        "    # More realistic improvement calculation\n",
        "    for student in score_matrix.index:\n",
        "        profile_type = score_matrix.loc[student, 'profile_type']\n",
        "        improvement = improvement_factors.get(profile_type, 0.2)\n",
        "\n",
        "        for course in courses:\n",
        "            current_score = score_matrix.loc[student, course]\n",
        "            if current_score < 60:  # Focused improvement for weak areas\n",
        "                post_scores.loc[student, course] = min(100, current_score + (100 - current_score) * improvement)\n",
        "            else:\n",
        "                # Smaller improvement for already strong areas\n",
        "                post_scores.loc[student, course] = min(100, current_score * (1 + improvement / 3))\n",
        "\n",
        "    for course in courses:\n",
        "        for cluster_type in improvement_factors:\n",
        "            cluster_mask = score_matrix['profile_type'] == cluster_type\n",
        "            current_scores = score_matrix.loc[cluster_mask, course]\n",
        "            improvement = improvement_factors[cluster_type]\n",
        "            post_scores.loc[cluster_mask, course] = np.minimum(\n",
        "                current_scores + (100 - current_scores) * improvement,\n",
        "                100\n",
        "            )\n",
        "\n",
        "    # Visualization\n",
        "    visualizer = ResultVisualizer()\n",
        "\n",
        "    # Flatten scores for distribution plot\n",
        "    all_pre_scores = score_matrix[courses].values.flatten()\n",
        "    all_post_scores = post_scores[courses].values.flatten()\n",
        "    visualizer.plot_score_comparison(all_pre_scores, all_post_scores)\n",
        "\n",
        "    # Prepare cluster performance data\n",
        "    cluster_perf = score_matrix[['cluster', 'profile_type']].copy()\n",
        "    cluster_perf['pre_score'] = score_matrix[courses].mean(axis=1)\n",
        "    cluster_perf['post_score'] = post_scores[courses].mean(axis=1)\n",
        "    visualizer.plot_cluster_performance(cluster_perf.reset_index())\n",
        "\n",
        "    # NEW: Calculate comprehensive metrics\n",
        "    metrics = visualizer.calculate_performance_metrics(\n",
        "        score_matrix,\n",
        "        post_scores,\n",
        "        pathways,\n",
        "        courses,\n",
        "        cluster_profiles\n",
        "    )\n",
        "\n",
        "    # NEW: Visualize cluster improvements\n",
        "    visualizer.plot_improvement_by_cluster(metrics)\n",
        "\n",
        "    # NEW: Plot equity impact\n",
        "    visualizer.plot_equity_impact(metrics['improvements'])\n",
        "    print(\"Saved equity_impact.png\")\n",
        "\n",
        "    # ------------------\n",
        "    # 7. Output results\n",
        "    # ------------------\n",
        "    print(\"\\nRESULTS SUMMARY:\")\n",
        "    print(f\"- Students clustered into {optimal_k} performance groups\")\n",
        "    print(f\"- Average pre-intervention score: {np.mean(all_pre_scores):.1f}\")\n",
        "    print(f\"- Average post-intervention score: {np.mean(all_post_scores):.1f}\")\n",
        "    print(f\"- Average improvement: {np.mean(all_post_scores - all_pre_scores):.1f} points\")\n",
        "    print(f\"- Personalized pathways generated for {students_with_pathways} students\")\n",
        "    print(f\"- Average improvement: {metrics['overall_improvement']:.1f} points\")\n",
        "    print(f\"- Weak area resolution rate: {metrics['weak_area_resolution'] * 100:.1f}%\")\n",
        "    print(f\"- Average weekly study time: {metrics['avg_study_hours']:.1f} hours\")\n",
        "    print(f\"- Improvement equity (Gini): {metrics['gini_improvement']:.3f} (lower=better)\")\n",
        "\n",
        "    print(\"\\nCluster-Specific Improvements:\")\n",
        "    for cluster_id, data in metrics['cluster_improvements'].items():\n",
        "        profile = cluster_profiles[cluster_profiles['cluster'] == cluster_id]['profile_type'].iloc[0]\n",
        "        print(f\"  - Cluster {cluster_id} ({profile}): +{data['improvement']:.1f} points (n={data['size']})\")\n",
        "\n",
        "    # Find a student with a pathway\n",
        "    sample_student = next((sid for sid, path in pathways.items() if path), None)\n",
        "\n",
        "    if sample_student:\n",
        "        # Get original ID for sample student\n",
        "        original_id = reverse_mapping.get(sample_student, \"Unknown\")\n",
        "        profile_type = score_matrix.loc[sample_student, 'profile_type']\n",
        "\n",
        "        print(f\"\\nSample pathway for student {original_id} ({profile_type}):\")\n",
        "        for item in pathways[sample_student]:\n",
        "            course_name = courses[item['course_index']]\n",
        "            current_score = score_matrix.loc[sample_student, course_name]\n",
        "            print(f\"  - Course: {course_name} (Current Score: {current_score:.1f})\")\n",
        "            print(f\"    ZPD Level: {item['zpd_level']:.1f}\")\n",
        "            print(f\"    Study Hours: {item['study_hours']}\")\n",
        "            print(f\"    Resources: {item['resources'][0]}\")\n",
        "\n",
        "    print(\"\\nVisualizations saved:\")\n",
        "    print(\"- bic_optimization.png: Cluster selection using BIC\")\n",
        "    print(\"- performance_profiles.png: Cluster performance profiles\")\n",
        "    print(\"- score_distribution_comparison.png: Pre/post score distributions\")\n",
        "    print(\"- cluster_performance.png: Improvement by cluster\")\n",
        "    print(\"- cluster_validation.png: Cluster quality metrics\")\n",
        "\n",
        "    print(\"\\nExecution complete. Results saved in Colab environment.\" if IN_COLAB else \"Execution complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8a0403ac51fb4fc6bcd0a955b14f81f8",
            "78f0cf69cc8f41188139b1be810a774b",
            "48e8b313c0a649f3bd3b03b2258fccd3",
            "809ab68dabef43d3bddd50a9b5dfd836",
            "3619ee2e8d6d43e68c94248fa356a22a",
            "3282f683851641518d7bdf6016e7427d",
            "1fdab914a9ff437ba7fc074cf2a2b7c1",
            "e5f3e3a13a154847977442503ed31b96",
            "5352886809d840379169777439ebd883",
            "cc48271bc87143e2abb6840f75de7f42",
            "0ba8dadc4b5b48bca7fb3d11b0f14249",
            "91e87cb9f12041e7b99b198849fb4e15",
            "35d287401d8b4bc883e455b075931add",
            "05138b65180b4296898d1c77fad4382e",
            "ba334feccfb140e0bd85642f1207820f",
            "b1cd50b6230d4208943461aa20df8d7a",
            "cf2c6d74473b4728964a9b933a16339a",
            "bcc7f13c930340de9ea0a74b00ae3c2b",
            "8b42fa8c985e45da81f188248604be48",
            "23946379f4674911a698f2727ea14733",
            "bb0424e7a14547bd904bb67352fd7f63",
            "83f0960f6ef640d8a28a87cf0096b191",
            "f994796f69a2441881e7ecb23e08a2de",
            "8e80dd31a9d4492da1402dd9434160e6",
            "a90f89bc81404ed7991dbd24959ed933",
            "36b2facb2f56451181a2cedf0efdc7d9",
            "6c185b7cc14141b9820bb3a2570c05fc",
            "46f7bcaf8f76437b8a924999f9a4e11f",
            "9e29d95cddb54dab8bb14aa3c5133fb9",
            "4577ec20788d4190a65891d424a0abdf",
            "0961adecfc7a4063a047af73b9f9be6e",
            "e59fd93149934d07a749ce2fc524fdcd",
            "e7d4ff72e6cd4fd89dce5c437238e4e9",
            "6f0a59457b3146f09e780b2dcc64beea",
            "628dbc403a9f476396b740875a639d0c",
            "f33d3b4cb2bb4b66950ee5627767029b",
            "e6939fd60fb84cb7b4cd9d1cfff1a70d",
            "b2c76b60e3ed46c2802bccaf3dce46b5",
            "364470626d904de98d97cab389457f39",
            "d46599d1c77847258b6c3b1b2e27aa51",
            "4a8652777ec04518b884699530103090",
            "c279becbaf9a4339bd9d957c164d2eba",
            "6600708d4e7e42ae961993c43a12ae53",
            "2b693e738f9348d9aa1d2b42336c0bc8",
            "c753fb5996ec4ed38b098053611fd8e1",
            "79424982a3084e41ae43df01414189ce",
            "28878c11a0d344929dd31ab7425e4f20",
            "7533e6687c0e485bab83f28914b612f5",
            "eaeb6a09c5334be28584882414134aae",
            "3533cc3c05e34f7aadb4738a1ef13e4f",
            "75d5c5524bb7435d81d7d16077a76a70",
            "3eaf02b37fec482c9df962b06b9ae7f2",
            "4c1a80ae625d4626b80cbf389fe8e86a",
            "d1760b48d62142f2bbcbfa1ef00e07fc",
            "0a44318c514f41fa95aea0b28dc3f452",
            "d48e933c0804403e8e94a570a294caf0",
            "d54e7b447efa41f4a99f42af38f78a7b",
            "10817afe07ab43518eb4166275e277a8",
            "ce93493cbe154119b985339cfbc7d0e1",
            "04a5a874972d430e9074e20713e422fb",
            "2c4a732ea3b24284952f4d1b17b8eb59",
            "8f1bb645f78749cda653d2ac08c1344b",
            "509c7dee1f704090a19d68d016bdaa9c",
            "bae64d6f0dbc4928b5cf7b3667e3dd92",
            "ed346799da8d47e6a5fbcfe2b3c3a0d7",
            "209cfeebe9bb4b6a966f47837920f24d",
            "c0abc712f469464f99537622f03e4ad3",
            "ebed7b1af90d4584b736ba0801165191",
            "8a3991a2480443c1ad13fbf5a5fd4697",
            "2ebd7286daff47fb89b83e26275ebd97",
            "dbbe01671a38421b8235b990663ad8bf",
            "719bed6773504ba2971b3d16c9b523d8",
            "754ee199001747d0a04dbe0ba2405706",
            "173f1361e49d41ad89f13077c155941d",
            "48d8a1e7c12c447d8e7fd087f1a5cf4f",
            "ae5795e012c141e1b429ce4a7f504978",
            "23649b55e1764633baffdb93b4bf0756",
            "f1a31dacceab40ed87be786ef24ff155",
            "ddf2601798bc4c9c9a3e0051dd14ceab",
            "87012343534e48a0b0065dc16e5f81fb",
            "785ed485f6104be3a3b94ab1cecd07dd",
            "acd2ed93ba0c4ff1afbf544b37b5350e",
            "7d9e18f1583040dbbb3b62f58dc0620d",
            "8db05105cb274fe297dd3abb743560ec",
            "145610807a114956b504ef6465de2e16",
            "d5319c41b7364528beb8610d3c584c4b",
            "5dac60cdd59d4c45823283978a714d14",
            "cabf6c864b7744eaad7666630f6bde85",
            "47e55332e60848eab31576b92959a59e",
            "7658afcf3af7447095f71c847e4d92e2",
            "c6bb36b19140424f938cdbc5638506bc",
            "0413c084b439479da41791f1e5d876ec",
            "49737dae0aaa4b19a069c8dbc56a14f3",
            "dcf0e7df07d04b589fa694cb167d0e3d",
            "363633835ca8468e972c9f380504e474",
            "c9baa9454fbe4e2eac0305a199f965e5",
            "02f58656b18f48af8e192e0dfad7a7cf",
            "5ce8fe6fe5f34a978d9bdd7ad120f7eb",
            "3610aa9a3cf5472eaec720e487f6c876",
            "b818284cb19842f995e87f92636e85ad",
            "ea1aa1a1450c48548062f2c37abfb256",
            "284e17c70c4344cc93a67019c0e0006f",
            "1cc610b04752452cad712b59062a6be3",
            "2dc2975ba38e4995ad3b0c2b0efb80f1",
            "e11a1658f96344569130f89c440b800e",
            "e003c9f4d37048efac24a2737abef176",
            "7a332ffd8516454ebb131a413346ad7f",
            "8c68efda1b8f4621aff8548060cb98d4",
            "e17882eaf4394fd0baf62396ffc9e27d",
            "86e820c50e5b481bbb270c30c44adf74",
            "f91ec36bb33746f4a96afec472449efc",
            "2bd15926344d461e86feb19d4fcdd808",
            "910e5b71cd2e4fc99ece6e20197d74c9",
            "d4729d1126494969b746aa2abe47e0d0",
            "526499a068884bd3a653e12253b30cb6",
            "d4e5f7113c384e32af74b9bc2e1e8aee",
            "29129740e4444cf9ad6ffc5d0a08b37a",
            "9fef5826f6474ced86abfefb5f333d99",
            "540563949bd64dfbb9f6363e070d5d59",
            "36d86e044bab44a4b62e61d703d88d16",
            "867ca38d3a1041b3b36b29aa7be7ebf2",
            "16ee8fdbfa9d4bcdbb61b8c6f460ea2c",
            "4ae17254226c42ebb026a0e50a703644",
            "e9fe988e2d2c4702b21260c39819c908",
            "f70f7d542f1f4b6395b943aad739274e",
            "2453638efe30469ebf24e104b65710cf",
            "e6636c996a0947e18d23f2af743d33b8",
            "d269babdbb3d41d09cfd8f10530f6776",
            "2f04850d0a5b4fa0ac0bbbecead4ff0d",
            "9989aeeaf5714c43b4aafdfa2d408b96",
            "8126f58e61ed413199f34c0e98d582df",
            "dd447498aef647d5a8d992b15462ec72"
          ]
        },
        "id": "RE0VVgxB9zKA",
        "outputId": "1a59e44c-e01f-4c7d-adb4-6d74d0dbd96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gensim not installed. Topic coherence metrics disabled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/hdbscan/plots.py:448: SyntaxWarning: invalid escape sequence '\\l'\n",
            "  axis.set_ylabel('$\\lambda$ value')\n",
            "/usr/local/lib/python3.12/dist-packages/hdbscan/robust_single_linkage_.py:175: SyntaxWarning: invalid escape sequence '\\{'\n",
            "  $max \\{ core_k(a), core_k(b), 1/\\alpha d(a,b) \\}$.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SANKOFA PATHWAYS: Personalized Learning System\n",
            "Soroti University Implementation (Google Colab)\n",
            "============================================================\n",
            "Created assessment template file: assessment_templates.csv\n",
            "\n",
            "[1/6] Generating synthetic dataset...\n",
            "Loaded assessment templates from assessment_templates.csv\n",
            "Saved dataset to soroti_engineering_dataset.csv\n",
            "[2/6] Preprocessing data with differential privacy...\n",
            "[3/6] Performing advanced hybrid topic modeling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a0403ac51fb4fc6bcd0a955b14f81f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91e87cb9f12041e7b99b198849fb4e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f994796f69a2441881e7ecb23e08a2de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f0a59457b3146f09e780b2dcc64beea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c753fb5996ec4ed38b098053611fd8e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d48e933c0804403e8e94a570a294caf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0abc712f469464f99537622f03e4ad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1a31dacceab40ed87be786ef24ff155"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47e55332e60848eab31576b92959a59e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b818284cb19842f995e87f92636e85ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f91ec36bb33746f4a96afec472449efc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: sentence-transformers/all-MiniLM-L6-v2\n",
            "Loading model: sentence-transformers/all-MiniLM-L6-v2\n",
            "Training models for comparison...\n",
            "- Training Original Hybrid...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16ee8fdbfa9d4bcdbb61b8c6f460ea2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Abort",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3059273481.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2369\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"- Training {name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mFINE_TUNE_BERT\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mIN_COLAB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_tune_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Original Hybrid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3059273481.py\u001b[0m in \u001b[0;36mfine_tune_bert\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineSimilarityLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         self.bert_model.fit(\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mtrain_objectives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_tune_steps\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/fit_mixin.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2486\u001b[0m         \u001b[0mgrad_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2488\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_on_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_training_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_train_begin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    557\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 self._wandb.init(\n\u001b[0m\u001b[1;32m    893\u001b[0m                     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WANDB_PROJECT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"huggingface\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0minit_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;31m# Need to build delay into this sentry capture because our exit hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;31m# mess with sentry's ability to send out errors before the program ends.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/analytics/sentry.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# this will messily add this \"reraise\" function to the stack trace,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# but hopefully it's not too bad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_safe_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_telemetry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m         \u001b[0mrun_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_warnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_run_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36mmaybe_login\u001b[0;34m(self, init_settings)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         wandb_login._login(\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify, referrer, update_api_key, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mkey_is_pre_configured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(self, referrer)\u001b[0m\n\u001b[1;32m    235\u001b[0m     ) -> Tuple[Optional[str], ApiKeyStatus]:\n\u001b[1;32m    236\u001b[0m         \u001b[0;34m\"\"\"Updates the global API key by prompting the user.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mApiKeyStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             directive = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_prompt_api_key\u001b[0;34m(self, referrer)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 key = apikey.prompt_api_key(\n\u001b[0m\u001b[1;32m    214\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local, referrer)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 )\n\u001b[1;32m    191\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtermlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_api_key_prompt_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferrer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_ask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLOGIN_CHOICE_NOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# TODO: Needs refactor as this needs to be handled by caller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhide_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAbort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAbort\u001b[0m: "
          ]
        }
      ]
    }
  ]
}